{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import Lib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import spacy\n",
        "# nlp = spacy.load(\"mr\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gjXnvSPbQzw7",
        "outputId": "e89921f8-b98a-4df6-cf8b-5313246ce217"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize.punkt import PunktSentenceTokenizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import PySimpleGUI as sg\n",
        "from langdetect import detect\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install nltk\n",
        "# !python -m spacy download en"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !python -m spacy download xx_ent_wiki_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Stemming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import spacy\n",
        "import codecs\n",
        "import mahaNLP\n",
        "# Load the spaCy Multilingual model\n",
        "from mahaNLP.preprocess import Preprocess\n",
        "nlp = spacy.load('xx_ent_wiki_sm')\n",
        "\n",
        "def load_text(file_path):\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            text = f.read()\n",
        "        return text\n",
        "    except FileNotFoundError:\n",
        "        print(f\"File not found: {file_path}\")\n",
        "        return None\n",
        "\n",
        "def summarize_marathi_text(text, num_sentences):  # Language detection and validation\n",
        "    detected_language = detect(text)\n",
        "    if detected_language != 'mr':  # Marathi language code is 'mr'\n",
        "        print(\"Please enter text in Marathi language.\")\n",
        "        return None  # Indicate failure or handle error message display\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Remove punctuation and digits\n",
        "    text = re.sub(r'[^a-zA-Z\\u0900-\\u097F\\s]', '', text)\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    return text\n",
        "\n",
        "def perform_marathi_stemming(text):\n",
        "    doc = text.split(\".\")\n",
        "    suffixes = {\n",
        "        1: [u\"ो\", u\"े\", u\"ू\", u\"ु\", u\"ी\", u\"ि\", u\"ा\", u\"च\"],\n",
        "        2: [u\"चा\", u\"चे\", u\"ने\", u\"नी\", u\"ना\", u\"ते\", u\"ीं\", u\"तील\", u\"ात\", u\"ाँ\", u\"ां\", u\"ों\", u\"ें\", u\"तच\", u\"ता\", u\"ही\",\n",
        "            u\"ले\"],\n",
        "        3: [u\"ाचा\", u\"ाचे\", u\"तील\", u\"ानी\", u\"ाने\", u\"ाना\", u\"ाते\", u\"ाती\", u\"ाता\", u\"तीं\", u\"तून\", u\"तील\", u\"तही\", u\"तपण\",\n",
        "            u\"कडे\", u\"ातच\", u\"हून\", u\"पणे\", u\"ाही\", u\"ाले\"],\n",
        "        4: [u\"मधले\", u\"ातील\", u\"च्या\", u\"न्या\", u\"ऱ्या\", u\"ख्या\", u\"वर\", u\"साठी\", u\"ातून\", u\"कडून\", u\"मुळे\", u\"वरून\",\n",
        "            u\"ातील\", u\"नीही\", u\"ातही\", u\"ातपण\", u\"ाकडे\", u\"पाशी\", u\"ाहून\", u\"ापणे\", u\"मधला\"],\n",
        "        5: [u\"ामधले\", u\"ाच्या\", u\"ान्या\", u\"ाऱ्या\", u\"ाख्या\", u\"ावर\", u\"ासाठी\", u\"पासून\", u\"ाकडून\", u\"ामुळे\", u\"ावरून\",\n",
        "            u\"कडेही\", u\"ानीही\", u\"ापाशी\", u\"ामधला\", u\"मध्ये\"],\n",
        "        6: [u\"पर्यंत\", u\"ापासून\", u\"ाकडेही\", u\"पूर्वक\", u\"लेल्या\", u\"ामध्ये\"],\n",
        "        7: [u\"ापर्यंत\", u\"प्रमाणे\", u\"तसुद्धा\", u\"ापूर्वक\", u\"ालेल्या\"],\n",
        "        8: [u\"ाप्रमाणे\", u\"ातसुद्धा\"],\n",
        "    }\n",
        "    preprocessed_text = []\n",
        "    # print(doc)\n",
        "    for each in doc:\n",
        "        tokens = each.split(' ')\n",
        "        cleaned_tokens = []\n",
        "        for tok in tokens:\n",
        "            if '-' in tok:\n",
        "                subtokens = tok.split('-')\n",
        "                cleaned_tokens.extend(subtokens)\n",
        "            else:\n",
        "                cleaned_tokens.append(tok.strip())\n",
        "\n",
        "        stems = []\n",
        "        for word in cleaned_tokens:\n",
        "            for i in range(8, 0, -1):\n",
        "                if len(word) > i + 1:\n",
        "                    for suf in suffixes[i]:\n",
        "                        if word.endswith(suf):\n",
        "                            word = word[:-i]\n",
        "            if word:\n",
        "                stems.append(word)\n",
        "        # if stems:\n",
        "        preprocessed_text.append(' '.join(stems))\n",
        "        # preprocessed_text += \".\"\n",
        "    return preprocessed_text\n",
        "\n",
        "# def perform_marathi_lemmatization(text):\n",
        "#     doc = nlp(text)\n",
        "#     lemmatized_words = [token.lemma_ for token in doc]\n",
        "#     return lemmatized_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "marathi_text = '''एका गावात एक छोटा सुंदर मुलगा होता. त्याच्या नावाचं 'राहुल' होतं. राहुलने प्रत्येक दिवस शाळेत आणि घरीचं खेळायला मनापासून वाढवलं. त्याच्या आईबाबांनी त्याला प्रत्येक वेळी सांगितलं, \"पुढचं शिका, पुढचं उभा आणि प्रत्येक क्षण आनंदाने जगा.\" \n",
        "एका दिवशी, राहुलने अपन्या मित्रांसोबत एका आग्रहाच्या खेळाचं स्वागत केलं. त्याच्या मनात वाटत होतं, \"माझं स्वप्न याचं सफर कसं सुरू होतं आणि कसं आनंदाने संपतं, ते सर्वांसाठी आणि माझ्या आईबाबांसाठी कसं उपयोगी होतं.\"\n",
        "त्याच्या आग्रहाच्या खेळाचं सुरू होतं आणि राहुल आणि त्याच्या मित्रांनी खूप आनंदाने खेळलं. त्यांना वेळ अद्याप अधिक मजा केला. राहुल आणि त्याच्या मित्रांनी साथीत खेळून खूप आनंदाने वेळ व्यतीत केलं.\n",
        "खेळाच्या शेवटी, राहुलने समजलं की, सफर महत्त्वाचं असतं. त्याचं उद्दिष्टं नक्कीपणा प्राप्त करणं आणि त्याचं स्वप्न पूर्ण करणं हे महत्त्वाचं आहे. त्याने निरंतर यशस्वीपणे काम केलं आणि आपल्या स्वप्नांचं सफर पूर्ण केलं.\n",
        "अखेर, त्याचं उद्दिष्ट साधलं आणि त्याचं स्वप्न साकार झालं. त्याचं परिश्रम आणि आत्मविश्वास ने त्याला प्रत्येकाला आणि समुदायाला प्रेरित केलं. राहुल आणि त्याचे मित्र एकत्र येऊन एकाच नात्याने सामाजिक सेवेत सहभागी झाले आणि स्वप्न साकार झाले.\n",
        "सद्यस्थितीत, राहुलने आपलं स्वप्न पूर्ण केलं, आणि त्याने प्रत्येक क्षण आनंदाने जगा.'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# marathi_text = \"\"\"विस्तीर्ण पसरलेलं जंगल, जंगलातच उगम पावलेली आणि गावाला वेढा देणारी, आजूबाजूच्या डोंगरांना हिरवाई देणारी वाघई नदी, एका बाजूला जंगल तर बाकी तीन बाजूंना नदी आणि डोंगरदऱ्यांनी वेढलेलं टुमदार गाव- वाघदरा. पूर्वी मुबलक असणाऱ्या वाघांच्या संख्येमुळे हे नाव या नदीला आणि गावाला लाभलं होतं. गावात एक प्राथमिक शाळा, एक पोस्टाची पेटी. बाकी सारे व्यवहार करायला गावकऱ्यांना २० किमी लांब जावं लागत असे. दादाराव पाटील आल्यापासून तशी गरज जास्त उरली नव्हती हेही खरं. फोन वरून बरच कामे होत, शिवाय वाड्यावर कॉम्प्युटरवर होण्यासारखी सारी सरकारी कामे होऊन जात होती. वाड्यावर म्हणजे दादाराव पाटलांच्या वाड्यावर..\n",
        "# जंगलाला लागून असलेला हा वाडा म्हणजे एक कोडं होतं. वाड्याचा पसारा मोठा म्हणजे जवळपास एकर भर.. नदी आणि जंगलाच्या आडोशाला जागा पाहून चाऱ्ही बाजूला पुरुषभर उंचीच्या दगडी भिंती जंगलाच्या बाजूला बांधलेला दोन मजली चौसोपी टुमदार वाडा. त्याच्यापुढं दगडी कुंपणाच्या बरोबरीनेच बांधलेला मोठाच्या मोठा गोठा, तबेला, कुत्र्यांसाठीची जाळीदार खोली. आणि अजून ८ खोल्या.. वाड्याच्या मुख्य दारापाशी दोन्ही बाजूला बैठकीच्या खोल्या. बाहेरून येणार जाणार सारे लोक आधी इथे थांबत आणि प्राथमिक चर्चा इथे होई, आणि मगच पुढं एन्ट्री. अर्थात गावाच्या कोणत्याही रहिवाश्याला वाड्यात बिनधोक प्रवेश होता. वाड्याच्या ह्या बैठकीत बसणारा बबन माने म्हणजे गावाचंच नाहीतर पंचक्रोशीचं चालतं बोलतं दप्तर.. खेडं असलं तरी गावात तरुण भरपूर होते आणि सारे शेती आणि त्याला पूरक व्यवसाय सांभाळून होते. बबन माने त्यातलाच एक हुन्नरी कलाकार.. पण याचं डोकं शेती ऐवजी इतर गोष्टीत जास्त, म्हणजे शेतकऱ्यांसाठी असणाऱ्या अनेक योजना शोधण्यापासून गावातल्या पोरापोरीची सोयरीक जुळवण्यापर्यंत, गावात येणाऱ्या प्रत्येक माणसाची जुजबी माहिती त्याच्यापर्यंत पोचायची, आणि वाड्यात येणार्यांची कुंडली.. आणि हे सगळं व्हायचं ते येणाऱ्या माणसाच्या नकळत. दादाराव पाटलांच्या वाड्यात वर्दळ कायम असायची. खरंतर दादाराव पाटलांचं आणि पाटलीणबाईंचं गावावर निःसीम प्रेम होतं. गाव तस बऱ्यापैकी लहानच होतं. जंगल आणि नदीमुळे गावात यायला जायला एकच रस्ता.. मुख्य हायवे पासून २५ किलोमीटर आत असलेलं हे एकुलतं एक गाव त्या रस्त्यावर होतं. फाट्यावर कायम एक रिक्षा किंवा जीप उभी असायची. त्यासोबत असलेली बबन्याच्या वडलांची चहा पानसुपारीची बारकी झोपडी, सोबतीला गावातलाच एखादा पोरगा दिवसभर आळीपाळीने असायचा.. तो आणि बबन्याचा बा सोडता माणसाचा मागमूस नाही. बबन्याचा बाप तसा सतत व्यस्त असायचा.. काथ्याचा दोर वळण्यात त्याचा हात कुणीच धरायचं नाही. बसल्या बसल्या दोर बनवायचा तर फाट्यावर झोपडीत बसून दोर वळ म्हणाला बबन्या. शिवाय एक अस्सल कारवानी उमदं कुत्रं आणून ठेवलं होतं ते एक. जनावर असं कि २००-३०० मीटर पासून जरी अनोळखी वास आला तर न भुकता बबन्याच्या बापाला जाऊन बरोबर सांगायचं. मग येणाऱ्या माणसाला थांबवून, पैसे देत असला तर विकत नाहीतर फुकट चहा पाजून बबन्याचा बाप, आलेला माणूस कोण, कुठला, गावात काय काम, किती दिस राहणार वगैरे बित्तम् बातमी काढायचा.. आपणच रघुला म्हणजे गावच्या रिक्षावाल्याला आवाज द्यायचा आणि गावात धाडायचा.. टोलनाकाच म्हणा ना.. एकुणात गाव आणि गावची माणसं बाकी जगापासून अलिप्तच राहायची..\n",
        "# एका सधन गावातले सधन आदर्श शेतकरी हीच ओळख दादांची जपली गेली त्यात बबनचा हात मोठा होता. दादांच्याकडे येणारी इतर कामे बबनकडून येत. कामाच्या काठिण्य पातळीनुसार माणूस ठरवला जाई. टेक्नॉलॉजिचा भरपूर वापर होत असला तरी तो कुठे करायचा आणि कुठे नाही याची जाणीव दादांना होती. काही कामे पैश्यांसाठी तर काही कामे निव्वळ माणुसकीपोटी केली जात होती.\n",
        "# पुण्यासारख्या मोठ्या शहरात एका गरीब पण होतकरू मुलाच्या घरात दिलेली वाघदर्याची मुलगी सुप्रिया, सुप्रियेच्या कॉलनीतली ती मुलगी जेव्हा रडत रडत घरी आली तेव्हा सुप्रिया वाण्याच्या दुकानात काहीतरी घ्यायला गेलेली. संध्याकाळी वेळ. आणि मुलीची एकंदर अवस्था पाहून सुप्रियेला गलबलून आलं. जेमतेम १७ वर्षाची ती नाजूक पोर, विस्कटलेले केस, ड्रेस पाठीवर फाटलेला, रक्ताळलेला ओठ. वाघदऱ्याच्या सुरक्षित वातावरणात वाढलेली सुप्रियेच्या काळजात चर्रर्र झालं. दोन वर्षांपूर्वी या वस्तीत आली असली तरी ती सगळ्यांना ओळखत होती. सुप्रिया त्या मुलीच्या- आरतीच्या पाठोपाठ घरी गेली. झाला प्रकार सांगायला आरती तयार नव्हती, पण सुप्रियेच्या मायेच्या स्पर्शाने तिला वाचा फुटली. जसजशी आरती सांगत होती, तसतशी सुप्रिया एकाच वेळी दुखावत आणि संतापत होती. सगळं ऐकून घेतल्यावर सुप्रियेने घरचा रस्ता धरला.. मनात साठवून ठेवलेलं सारं काही घरी पोचल्याबरोबर तिने तिच्या आईला भडाभडा सांगून टाकलं.. आणि तिच्या आईने वाड्याचा रस्ता धरला..\n",
        "# सुप्रियाच्या आईने जशी सगळी हकीकत बबन्याला वाड्याच्या बैठकीत ऐकवली तशी ती निर्धास्त झाली. नाही म्हणायला तिलाही वाटलं होतंच कि असल्या गुंड असलेल्या वस्तीत आपली मुलगी कशी राहील.. पण वाड्यावर एकदा विषय पोहचला कि गावातलं कुणीही असो, ते निर्धास्त व्हायचे. बबन्याने लगोलग दादाराव पाटलांना वर्दी दिली. दादांनी सगळ्यात आधी आपला हुकमी एक्का जॉनीला परस्पर पुण्याला पाठवलं. जॉनी म्हणजे कोण तर गर्दीतला अनोळखी, लक्षात न राहणारा चेहरा. याचं खरं नाव कुणालाही माहित नव्हतं. जॉनीला ज्यांनी एकदा पाहिलं असेल ते दुसऱ्यांदा त्याला पाहिल्यावर ओळ्खतीलच अशी खात्री नव्हती इतका तो गर्दीत मिसळून जायचा. जॉनी पुण्याला पोहचला आणि कपडे- वेष बदलत एक दिवस मोन्याच्या मागोमाग फिरत त्याची माहिती काढत राहिला.. इकडे वाड्यावर दादांनी गावातला वैदू, सरकारी दवाखान्यातला डॉक्टर आणि बबन्याला घेऊन मिटिंग घेतली. वैदू वाड्याच्या मागच्या बाजूने जंगलात गेला, डॉक्टर आपल्या दवाखान्यात आणि बबन्याने गावातल्या भूषणला बोलावून घेतलं.. जॉनीने एव्हाना ठरल्या प्रोटोकॉलनुसार पुणे स्टेशनवर जाऊन मुंबई जाणारी गाडी पकडली. साधा कीपॅड मोबाईल असलेलं एक सावज हेरून त्याचा मोबाईल चोरला, आणि बबन्याला फोन करून म्हणाला कि \"हैवानानं पोसलेला लांडगा, पिसाळून गेलाय\" उत्तरादाखल बबनने फक्त म्हटलं, \"पत्र पाठवतो\". स्टेशनला उतरताना तो कीपॅड मोबाईल त्याच्या मूळ मालकाच्या पिशवीत पुन्हा पोहचला होता.\n",
        "# दुसऱ्या दिवशी भूषण पुणे स्टेशनजवळ पोस्ट ऑफिसला पोहचला त्याने जॉनीला दुरूनच हेरलं आणि बॅगमधून एक पाकीट काढून ते सहज जॉनीपर्यंत पोचते करून तो आल्यापावली निघून गेला.\n",
        "# पाकिटात एक लहानशी सिरिंज होती, ज्यात वैदूने दिलेला धोत्रा बियांचा विशुद्ध अर्क, आणि डॉक्टरने दिलेले स्ट्रॉंग aphrodisiac होते. लहानात लहान मात्रासुद्धा रक्तदाब वाढवून जीव घेईल असं ते जहाल इंजेक्शन होतं. रात्री चायनीजच्या गाड्याच्या जवळपासच ७ वाजल्यापासूनच जॉनी आपल्या शिकारीची वाट पाहत बसला होता. एक लहानसा धक्का, बारीकशी अगदी मच्छर चावला कि मुंगी अशी वाटावी अशी कळ, आणि थेट मुख्य धमनीत पोहोचलेलं ते जहाल विष.. मोन्याचा विषय आटोपला असला तरी त्याचा मालक अजून बाकी होता..\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# marathi_text = input(\"Enter your Marathi text:\\n\")\n",
        "# num_sentences = int(input(\"Enter the desired number of sentences for the summary: \"))\n",
        "num_sentences = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "preproceed_text = preprocess_text(marathi_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# perform_marathi_lemmatization(preproceed_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "Stemmed_text = perform_marathi_stemming(marathi_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['एक गाव एक छोट सुंदर मुलग हो',\n",
              " \"त्य नावाचं 'राहुल' होतं\",\n",
              " 'राहुल प्रत्येक दिवस शाळेत आण घरीचं खेळायल मन वाढवलं',\n",
              " 'त्य आईबाब त्याल प्रत्येक वेळ सांगितलं, \"पुढचं शिका, पुढचं उभ आण प्रत्येक क्षण आनंद जग',\n",
              " '\" एक दिवशी, राहुल अप मित्रांसोबत एक आग्रह खेळाचं स्वागत केलं',\n",
              " 'त्य मन वाटत होतं, \"माझं स्वप्न याचं सफर कसं सुर होतं आण कसं आनंद संपतं, ते सर्व आण माझ्य आईबाब कसं उपयोग होतं',\n",
              " '\"\\nत्य आग्रह खेळाचं सुर होतं आण राहुल आण त्य मित्र खूप आनंद खेळलं',\n",
              " 'त्य वेळ अद्याप अधिक मज केल',\n",
              " 'राहुल आण त्य मित्र साथीत खेळून खूप आनंद वेळ व्यतीत केलं',\n",
              " 'खेळ शेवटी, राहुल समजलं की, सफर महत्त्वाचं असतं',\n",
              " 'त्याचं उद्दिष्टं नक्कीपण प्राप्त करणं आण त्याचं स्वप्न पूर्ण करणं हे महत्त्वाचं आह',\n",
              " 'त्य निरंतर यशस्व काम केलं आण आपल्य स्वप्नांचं सफर पूर्ण केलं',\n",
              " 'अखेर, त्याचं उद्दिष्ट साधलं आण त्याचं स्वप्न साकार झालं',\n",
              " 'त्याचं परिश्रम आण आत्मविश्वास ने त्याल प्रत्येकाल आण समुदायाल प्रेरित केलं',\n",
              " 'राहुल आण त्य मित्र एकत्र येऊन एका नात्य सामाजिक सेवेत सहभाग झा आण स्वप्न साकार झा',\n",
              " 'सद्यस्थितीत, राहुल आपलं स्वप्न पूर्ण केलं, आण त्य प्रत्येक क्षण आनंद जग',\n",
              " '']"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Stemmed_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install fuzzywuzzy\n",
        "# !pip install --upgrade fuzzywuzzy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_bigram_length(sentence):\n",
        "    # Tokenize the sentence into words\n",
        "    words = sentence.split()\n",
        "    \n",
        "    # Generate bigrams\n",
        "    bigrams = [(words[i], words[i + 1]) for i in range(len(words) - 1)]\n",
        "    \n",
        "    # Return the number of bigrams\n",
        "    return len(bigrams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_trigram_length(sentence):\n",
        "    # Tokenize the sentence into words\n",
        "    words = sentence.split()\n",
        "    \n",
        "    # Generate trigrams\n",
        "    trigrams = [(words[i], words[i + 1], words[i + 2]) for i in range(len(words) - 2)]\n",
        "    \n",
        "    # Return the number of trigrams\n",
        "    return len(trigrams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_tf_isf(sentence):\n",
        "    # Tokenize the sentence into words\n",
        "    words = sentence.split()\n",
        "    \n",
        "    # Calculate term frequency\n",
        "    term_freq = {}\n",
        "    for word in words:\n",
        "        term_freq[word] = term_freq.get(word, 0) + 1\n",
        "    \n",
        "    # Calculate inverse sentence frequency\n",
        "    inverse_sentence_freq = 1 / len(words)\n",
        "    \n",
        "    # Calculate TF-ISF for each term\n",
        "    tf_isf = {}\n",
        "    for word, freq in term_freq.items():\n",
        "        tf_isf[word] = freq * inverse_sentence_freq\n",
        "\n",
        "    summ = 0\n",
        "    for val in  tf_isf.values():\n",
        "        summ += val\n",
        "    tf_isf = summ/len(words)\n",
        "    \n",
        "    return tf_isf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_sentence_length_factor(sentence, max_sentence_length):\n",
        "    # Tokenize the sentence into words\n",
        "    words = sentence.split()\n",
        "    \n",
        "    # Calculate the length of the sentence\n",
        "    sentence_length = len(words)\n",
        "    \n",
        "    # Calculate the sentence length factor\n",
        "    sentence_length_factor = sentence_length / max_sentence_length\n",
        "    \n",
        "    return sentence_length_factor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_numeric_tokens_ratio(sentence):\n",
        "    # Tokenize the sentence into words\n",
        "    words = sentence.split()\n",
        "    \n",
        "    # Count the number of numeric tokens\n",
        "    numeric_count = sum(1 for word in words if word.isdigit())\n",
        "    \n",
        "    # Calculate the ratio of numeric tokens to total tokens\n",
        "    if len(words) > 0:\n",
        "        numeric_tokens_ratio = numeric_count / len(words)\n",
        "    else:\n",
        "        numeric_tokens_ratio = 0.0\n",
        "    \n",
        "    return numeric_tokens_ratio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_pos_factor(total_sentences, current_pos):\n",
        "    \"\"\"\n",
        "    Calculate the Position Factor (POS factor) for a given sentence.\n",
        "\n",
        "    Parameters:\n",
        "    total_sentences (int): Total number of sentences in the document.\n",
        "    current_pos (int): Position of the current sentence within the document.\n",
        "\n",
        "    Returns:\n",
        "    float: The calculated Position Factor.\n",
        "    \"\"\"\n",
        "    return (total_sentences - current_pos) / total_sentences\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_thematic_number(sentence, keywords):\n",
        "    \"\"\"\n",
        "    Calculate the Thematic Number for a given sentence.\n",
        "\n",
        "    Parameters:\n",
        "    sentence (str): The input sentence.\n",
        "    keywords (list): List of keywords representing main themes or topics of the document.\n",
        "\n",
        "    Returns:\n",
        "    float: The calculated Thematic Number.\n",
        "    \"\"\"\n",
        "    # Tokenize the sentence into words\n",
        "    words = sentence.split()\n",
        "    \n",
        "    # Count the number of keywords present in the sentence\n",
        "    keyword_count = sum(1 for word in words if word in keywords)\n",
        "    \n",
        "    # Calculate the ratio of keywords in the sentence to the total number of keywords\n",
        "    if len(keywords) > 0:\n",
        "        thematic_number = keyword_count / len(keywords)\n",
        "    else:\n",
        "        thematic_number = 0.0\n",
        "    \n",
        "    return thematic_number\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "def calculate_centroid(preproceed_text):\n",
        "    \"\"\"\n",
        "    Calculate the centroid of the document.\n",
        "\n",
        "    Parameters:\n",
        "    preproceed_text (list): List of preprocessed sentences from the document.\n",
        "\n",
        "    Returns:\n",
        "    dict: A dictionary representing the centroid of the document.\n",
        "    \"\"\"\n",
        "#     # Initialize a TF-IDF vectorizer\n",
        "#     vectorizer = TfidfVectorizer()\n",
        "    \n",
        "#     # Fit and transform the preprocessed text to compute TF-IDF vectors\n",
        "#     tfidf_matrix = vectorizer.fit_transform(preproceed_text)\n",
        "#     print(\"shape:\", tfidf_matrix.shape)\n",
        "\n",
        "#    # Compute the centroid vector\n",
        "#     centroid_vector = np.mean(tfidf_matrix, axis=0)\n",
        "#     centroid_dict = {feature: value for feature, value in zip(vectorizer.get_feature_names_out(), centroid_vector.toarray()[0])}\n",
        "#     print(centroid_dict)\n",
        "\n",
        "#     return centroid_dict\n",
        "    vectorizer = CountVectorizer()\n",
        "    X = vectorizer.fit_transform(preproceed_text)\n",
        "\n",
        "    # Calculate the centroid (average vector) of the Marathi sentences\n",
        "    centroid = np.mean(X.toarray(), axis=0)\n",
        "    # print(centroid)\n",
        "    return vectorizer, centroid\n",
        "\n",
        "    # Function to calculate cosine similarity between a Marathi sentence and the centroid\n",
        "def cosine_similarity_with_centroid_marathi(sentence, centroid, vectorizer):\n",
        "    sentence_vector = vectorizer.transform(sentence).toarray()\n",
        "    similarity = cosine_similarity(sentence_vector, [centroid])\n",
        "    print(\"similarity: \", similarity[0][0])\n",
        "    return similarity[0][0]\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "def convert_sparse_to_dense_general(sparse_matrix, num_rows, num_cols):\n",
        "    \"\"\"\n",
        "    Convert a sparse matrix to a dense matrix with the specified dimensions.\n",
        "\n",
        "    Args:\n",
        "        sparse_matrix (scipy.sparse.csr_matrix): The input sparse matrix.\n",
        "        num_rows (int): The desired number of rows in the dense matrix.\n",
        "        num_cols (int): The desired number of columns in the dense matrix.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: A dense matrix with the specified dimensions.\n",
        "    \"\"\"\n",
        "    dense_matrix = np.zeros((num_rows, num_cols), dtype=sparse_matrix.dtype)\n",
        "    rows, cols = sparse_matrix.nonzero()\n",
        "    data = sparse_matrix.data\n",
        "\n",
        "    for row, col, value in zip(rows, cols, data):\n",
        "        if row < num_rows and col < num_cols:\n",
        "            dense_matrix[row, col] = value\n",
        "\n",
        "    return dense_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "\n",
        "\n",
        "def calculate_cosine_similarity(sentence, document_centroid):\n",
        "    \"\"\"\n",
        "    Calculate the cosine similarity between a sentence vector and the document centroid.\n",
        "\n",
        "    Parameters:\n",
        "    sentence (str): Sentence text.\n",
        "    document_centroid (dict): Document centroid represented as a dictionary of TF-IDF values.\n",
        "\n",
        "    Returns:\n",
        "    float: Cosine similarity score.\n",
        "    \"\"\"\n",
        "    # Convert document centroid dictionary to a sparse matrix\n",
        "    document_vector = np.array([document_centroid])\n",
        "    \n",
        "    # Vectorize the sentence using the same TF-IDF vectorizer used for the document centroid\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    sentence_vector = vectorizer.fit_transform([sentence])\n",
        "    sentence_vector = convert_sparse_to_dense_general(sentence_vector, 1, 59)\n",
        "\n",
        "    print(document_centroid)\n",
        "    cosine_sim = cosine_similarity(sentence_vector, document_centroid)[0][0]\n",
        "    print(cosine_sim)\n",
        "    return cosine_sim\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_sentence_scores(stemmed_text, total_sentences,  max_sentence_length):\n",
        "    \"\"\"\n",
        "    Calculate scores for each sentence based on different metrics.\n",
        "\n",
        "    Parameters:\n",
        "    stemmed_text (list): List of preprocessed and stemmed sentences.\n",
        "    total_sentences (int): Total number of sentences in the document.\n",
        "    document_centroid (dict): Centroid of the document.\n",
        "    max_sentence_length (int): Length of the longest sentence in the document.\n",
        "\n",
        "    Returns:\n",
        "    dict: Dictionary containing sentence indices as keys and corresponding scores as values.\n",
        "    \"\"\"\n",
        "    sentence_scores = {}\n",
        "    print(stemmed_text)\n",
        "    for idx, sentence in enumerate(stemmed_text):\n",
        "        try:\n",
        "        # Calculate POS factor\n",
        "            pos_factor = calculate_pos_factor(total_sentences, idx + 1)\n",
        "            print(\"pos fact:\",pos_factor)\n",
        "\n",
        "            # Calculate Bigram token length\n",
        "            bigram_length = calculate_bigram_length(sentence)\n",
        "            print(\"bigram length:\",bigram_length)\n",
        "\n",
        "            # Calculate Trigram token length\n",
        "            trigram_length = calculate_trigram_length(sentence)\n",
        "            print(\"trigram length:\",trigram_length)\n",
        "\n",
        "            # Calculate TF-ISF vector\n",
        "            tf_isf = calculate_tf_isf(sentence)\n",
        "            print(\"tf isf:\",tf_isf)\n",
        "\n",
        "            # Calculate cosine similarity\n",
        "            # cosine_similarity_score = cosine_similarity_with_centroid_marathi(sentence, document_centroid, vectorizer)\n",
        "            # print(\"cosine similarity:\",cosine_similarity_score)\n",
        "\n",
        "            # Calculate thematic number\n",
        "            thematic_number = calculate_thematic_number(sentence,[])\n",
        "            print(\"thematic:\",thematic_number)\n",
        "\n",
        "            # Calculate sentence length factor\n",
        "            sentence_length_factor = calculate_sentence_length_factor(sentence, max_sentence_length)\n",
        "            print(\"sent len fac:\",sentence_length_factor)\n",
        "\n",
        "            # Calculate numeric tokens ratio\n",
        "            numeric_tokens_ratio = calculate_numeric_tokens_ratio(sentence)\n",
        "            print(\"num tockens ratio:\",numeric_tokens_ratio)\n",
        "\n",
        "            # Calculate sentence score using a combination of metrics\n",
        "            sentence_score = (\n",
        "                pos_factor\n",
        "                + bigram_length\n",
        "                + trigram_length\n",
        "                + tf_isf\n",
        "                # + cosine_similarity_score\n",
        "                + thematic_number\n",
        "                + sentence_length_factor\n",
        "                + numeric_tokens_ratio\n",
        "            )\n",
        "        except: \n",
        "            sentence_score = 0\n",
        "        # Store the sentence score\n",
        "        sentence_scores[idx] = sentence_score\n",
        "\n",
        "    return sentence_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_summary(original_text, stemmed_text, sentence_scores, num_sentences=5):\n",
        "    \"\"\"\n",
        "    Generate a summary based on the calculated sentence scores.\n",
        "\n",
        "    Parameters:\n",
        "    stemmed_text (list): List of preprocessed and stemmed sentences.\n",
        "    sentence_scores (dict): Dictionary containing sentence indices as keys and corresponding scores as values.\n",
        "    num_sentences (int): Number of sentences to include in the summary. Default is 5.\n",
        "\n",
        "    Returns:\n",
        "    str: The generated summary.\n",
        "    \"\"\"\n",
        "    # Sort the sentences based on scores (in descending order)\n",
        "    sorted_sentences = sorted(sentence_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    # Select the top num_sentences sentences for the summary\n",
        "    selected_sentences = sorted_sentences[:num_sentences]\n",
        "    \n",
        "    # Sort selected sentences based on their original order\n",
        "    selected_sentences.sort(key=lambda x: x[0])\n",
        "    doc = original_text.split(\".\")\n",
        "    # Generate the summary by joining selected sentences\n",
        "    print(doc)\n",
        "    for idx, _ in selected_sentences:\n",
        "        print(idx)\n",
        "    summary = ' '.join(doc[idx] for idx, _ in selected_sentences)\n",
        "    \n",
        "    return summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(sentence_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['एक गाव एक छोट सुंदर मुलग हो', \"त्य नावाचं 'राहुल' होतं\", 'राहुल प्रत्येक दिवस शाळेत आण घरीचं खेळायल मन वाढवलं', 'त्य आईबाब त्याल प्रत्येक वेळ सांगितलं, \"पुढचं शिका, पुढचं उभ आण प्रत्येक क्षण आनंद जग', '\" एक दिवशी, राहुल अप मित्रांसोबत एक आग्रह खेळाचं स्वागत केलं', 'त्य मन वाटत होतं, \"माझं स्वप्न याचं सफर कसं सुर होतं आण कसं आनंद संपतं, ते सर्व आण माझ्य आईबाब कसं उपयोग होतं', '\"\\nत्य आग्रह खेळाचं सुर होतं आण राहुल आण त्य मित्र खूप आनंद खेळलं', 'त्य वेळ अद्याप अधिक मज केल', 'राहुल आण त्य मित्र साथीत खेळून खूप आनंद वेळ व्यतीत केलं', 'खेळ शेवटी, राहुल समजलं की, सफर महत्त्वाचं असतं', 'त्याचं उद्दिष्टं नक्कीपण प्राप्त करणं आण त्याचं स्वप्न पूर्ण करणं हे महत्त्वाचं आह', 'त्य निरंतर यशस्व काम केलं आण आपल्य स्वप्नांचं सफर पूर्ण केलं', 'अखेर, त्याचं उद्दिष्ट साधलं आण त्याचं स्वप्न साकार झालं', 'त्याचं परिश्रम आण आत्मविश्वास ने त्याल प्रत्येकाल आण समुदायाल प्रेरित केलं', 'राहुल आण त्य मित्र एकत्र येऊन एका नात्य सामाजिक सेवेत सहभाग झा आण स्वप्न साकार झा', 'सद्यस्थितीत, राहुल आपलं स्वप्न पूर्ण केलं, आण त्य प्रत्येक क्षण आनंद जग', '']\n",
            "pos fact: 0.9411764705882353\n",
            "bigram length: 6\n",
            "trigram length: 5\n",
            "tf isf: 0.14285714285714282\n",
            "thematic: 0.0\n",
            "sent len fac: 0.30434782608695654\n",
            "num tockens ratio: 0.0\n",
            "pos fact: 0.8823529411764706\n",
            "bigram length: 3\n",
            "trigram length: 2\n",
            "tf isf: 0.25\n",
            "thematic: 0.0\n",
            "sent len fac: 0.17391304347826086\n",
            "num tockens ratio: 0.0\n",
            "pos fact: 0.8235294117647058\n",
            "bigram length: 8\n",
            "trigram length: 7\n",
            "tf isf: 0.11111111111111113\n",
            "thematic: 0.0\n",
            "sent len fac: 0.391304347826087\n",
            "num tockens ratio: 0.0\n",
            "pos fact: 0.7647058823529411\n",
            "bigram length: 14\n",
            "trigram length: 13\n",
            "tf isf: 0.06666666666666667\n",
            "thematic: 0.0\n",
            "sent len fac: 0.6521739130434783\n",
            "num tockens ratio: 0.0\n",
            "pos fact: 0.7058823529411765\n",
            "bigram length: 10\n",
            "trigram length: 9\n",
            "tf isf: 0.09090909090909093\n",
            "thematic: 0.0\n",
            "sent len fac: 0.4782608695652174\n",
            "num tockens ratio: 0.0\n",
            "pos fact: 0.6470588235294118\n",
            "bigram length: 22\n",
            "trigram length: 21\n",
            "tf isf: 0.04347826086956521\n",
            "thematic: 0.0\n",
            "sent len fac: 1.0\n",
            "num tockens ratio: 0.0\n",
            "pos fact: 0.5882352941176471\n",
            "bigram length: 13\n",
            "trigram length: 12\n",
            "tf isf: 0.07142857142857141\n",
            "thematic: 0.0\n",
            "sent len fac: 0.6086956521739131\n",
            "num tockens ratio: 0.0\n",
            "pos fact: 0.5294117647058824\n",
            "bigram length: 5\n",
            "trigram length: 4\n",
            "tf isf: 0.16666666666666666\n",
            "thematic: 0.0\n",
            "sent len fac: 0.2608695652173913\n",
            "num tockens ratio: 0.0\n",
            "pos fact: 0.47058823529411764\n",
            "bigram length: 10\n",
            "trigram length: 9\n",
            "tf isf: 0.09090909090909093\n",
            "thematic: 0.0\n",
            "sent len fac: 0.4782608695652174\n",
            "num tockens ratio: 0.0\n",
            "pos fact: 0.4117647058823529\n",
            "bigram length: 7\n",
            "trigram length: 6\n",
            "tf isf: 0.125\n",
            "thematic: 0.0\n",
            "sent len fac: 0.34782608695652173\n",
            "num tockens ratio: 0.0\n",
            "pos fact: 0.35294117647058826\n",
            "bigram length: 12\n",
            "trigram length: 11\n",
            "tf isf: 0.0769230769230769\n",
            "thematic: 0.0\n",
            "sent len fac: 0.5652173913043478\n",
            "num tockens ratio: 0.0\n",
            "pos fact: 0.29411764705882354\n",
            "bigram length: 10\n",
            "trigram length: 9\n",
            "tf isf: 0.09090909090909091\n",
            "thematic: 0.0\n",
            "sent len fac: 0.4782608695652174\n",
            "num tockens ratio: 0.0\n",
            "pos fact: 0.23529411764705882\n",
            "bigram length: 8\n",
            "trigram length: 7\n",
            "tf isf: 0.11111111111111113\n",
            "thematic: 0.0\n",
            "sent len fac: 0.391304347826087\n",
            "num tockens ratio: 0.0\n",
            "pos fact: 0.17647058823529413\n",
            "bigram length: 10\n",
            "trigram length: 9\n",
            "tf isf: 0.09090909090909093\n",
            "thematic: 0.0\n",
            "sent len fac: 0.4782608695652174\n",
            "num tockens ratio: 0.0\n",
            "pos fact: 0.11764705882352941\n",
            "bigram length: 15\n",
            "trigram length: 14\n",
            "tf isf: 0.0625\n",
            "thematic: 0.0\n",
            "sent len fac: 0.6956521739130435\n",
            "num tockens ratio: 0.0\n",
            "pos fact: 0.058823529411764705\n",
            "bigram length: 11\n",
            "trigram length: 10\n",
            "tf isf: 0.08333333333333333\n",
            "thematic: 0.0\n",
            "sent len fac: 0.5217391304347826\n",
            "num tockens ratio: 0.0\n",
            "pos fact: 0.0\n",
            "bigram length: 0\n",
            "trigram length: 0\n",
            "['एका गावात एक छोटा सुंदर मुलगा होता', \" त्याच्या नावाचं 'राहुल' होतं\", ' राहुलने प्रत्येक दिवस शाळेत आणि घरीचं खेळायला मनापासून वाढवलं', ' त्याच्या आईबाबांनी त्याला प्रत्येक वेळी सांगितलं, \"पुढचं शिका, पुढचं उभा आणि प्रत्येक क्षण आनंदाने जगा', '\" \\nएका दिवशी, राहुलने अपन्या मित्रांसोबत एका आग्रहाच्या खेळाचं स्वागत केलं', ' त्याच्या मनात वाटत होतं, \"माझं स्वप्न याचं सफर कसं सुरू होतं आणि कसं आनंदाने संपतं, ते सर्वांसाठी आणि माझ्या आईबाबांसाठी कसं उपयोगी होतं', '\"\\nत्याच्या आग्रहाच्या खेळाचं सुरू होतं आणि राहुल आणि त्याच्या मित्रांनी खूप आनंदाने खेळलं', ' त्यांना वेळ अद्याप अधिक मजा केला', ' राहुल आणि त्याच्या मित्रांनी साथीत खेळून खूप आनंदाने वेळ व्यतीत केलं', '\\nखेळाच्या शेवटी, राहुलने समजलं की, सफर महत्त्वाचं असतं', ' त्याचं उद्दिष्टं नक्कीपणा प्राप्त करणं आणि त्याचं स्वप्न पूर्ण करणं हे महत्त्वाचं आहे', ' त्याने निरंतर यशस्वीपणे काम केलं आणि आपल्या स्वप्नांचं सफर पूर्ण केलं', '\\nअखेर, त्याचं उद्दिष्ट साधलं आणि त्याचं स्वप्न साकार झालं', ' त्याचं परिश्रम आणि आत्मविश्वास ने त्याला प्रत्येकाला आणि समुदायाला प्रेरित केलं', ' राहुल आणि त्याचे मित्र एकत्र येऊन एकाच नात्याने सामाजिक सेवेत सहभागी झाले आणि स्वप्न साकार झाले', '\\nसद्यस्थितीत, राहुलने आपलं स्वप्न पूर्ण केलं, आणि त्याने प्रत्येक क्षण आनंदाने जगा', '']\n",
            "3\n",
            "5\n",
            "6\n",
            "10\n",
            "14\n",
            "summary:  त्याच्या आईबाबांनी त्याला प्रत्येक वेळी सांगितलं, \"पुढचं शिका, पुढचं उभा आणि प्रत्येक क्षण आनंदाने जगा  त्याच्या मनात वाटत होतं, \"माझं स्वप्न याचं सफर कसं सुरू होतं आणि कसं आनंदाने संपतं, ते सर्वांसाठी आणि माझ्या आईबाबांसाठी कसं उपयोगी होतं \"\n",
            "त्याच्या आग्रहाच्या खेळाचं सुरू होतं आणि राहुल आणि त्याच्या मित्रांनी खूप आनंदाने खेळलं  त्याचं उद्दिष्टं नक्कीपणा प्राप्त करणं आणि त्याचं स्वप्न पूर्ण करणं हे महत्त्वाचं आहे  राहुल आणि त्याचे मित्र एकत्र येऊन एकाच नात्याने सामाजिक सेवेत सहभागी झाले आणि स्वप्न साकार झाले\n"
          ]
        }
      ],
      "source": [
        "# Calculate total sentences\n",
        "total_sentences = len(Stemmed_text)\n",
        "\n",
        "# Calculate document centroid\n",
        "# vectorizer, document_centroid = calculate_centroid(Stemmed_text)\n",
        "\n",
        "# Calculate maximum sentence length\n",
        "max_sentence_length = max(len(sentence.split()) for sentence in Stemmed_text)\n",
        "\n",
        "# Calculate sentence scores\n",
        "sentence_scores = calculate_sentence_scores(Stemmed_text, total_sentences, max_sentence_length)\n",
        "Original_text = marathi_text\n",
        "# Generate summary\n",
        "summary = generate_summary(Original_text, Stemmed_text, sentence_scores, num_sentences)\n",
        "print(\"summary:\", summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # # Summarize the text\n",
        "# summary = generate_summary(Original_text, Stemmed_text, sentence_scores, num_sentences)\n",
        "# print(\"Summary: \",summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## GUI PART"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "invalid literal for int() with base 10: ''",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[21], line 111\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGenerate Summary\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (event \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m values[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-TEXT-\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;66;03m# Get input values\u001b[39;00m\n\u001b[0;32m    110\u001b[0m     marathi_text \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-TEXT-\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m--> 111\u001b[0m     num_sentences \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-NUM_SENTENCES-\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;66;03m# Preprocess text\u001b[39;00m\n\u001b[0;32m    114\u001b[0m     preprocessed_text \u001b[38;5;241m=\u001b[39m preprocess_text(marathi_text)\n",
            "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "import PySimpleGUI as sg\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Define the layout of the GUI\n",
        "layout = [\n",
        "    [sg.Text('Enter your Marathi text:')],\n",
        "    [sg.Multiline(key='-TEXT-', size=(800, 12))],\n",
        "    [sg.Text('Enter the desired number of sentences for the summary:')],\n",
        "    [sg.InputText(key='-NUM_SENTENCES-'), sg.Button('Generate Summary'), sg.Button('Reset'), sg.Button('Exit')],\n",
        "    [sg.Text(size=(60, 12), key='-OUTPUT-')],\n",
        "]\n",
        "\n",
        "# Create the window\n",
        "window = sg.Window('Marathi Text Summarizer', layout, size=(1000, 600))\n",
        "\n",
        "# Define the functions needed for summarization\n",
        "def preprocess_text(text):\n",
        "    # Preprocessing steps\n",
        "    return text\n",
        "\n",
        "# def calculate_centroid(preproceed_text):\n",
        "#     vectorizer = TfidfVectorizer()\n",
        "#     tfidf_matrix = vectorizer.fit_transform(preproceed_text)\n",
        "#     centroid_vector = np.mean(tfidf_matrix, axis=0)\n",
        "#     return centroid_vector\n",
        "\n",
        "def convert_sparse_to_dense_general(sparse_matrix, num_rows, num_cols):\n",
        "    dense_matrix = np.zeros((num_rows, num_cols), dtype=sparse_matrix.dtype)\n",
        "    rows, cols = sparse_matrix.nonzero()\n",
        "    data = sparse_matrix.data\n",
        "    for row, col, value in zip(rows, cols, data):\n",
        "        if row < num_rows and col < num_cols:\n",
        "            dense_matrix[row, col] = value\n",
        "    return dense_matrix\n",
        "\n",
        "# def calculate_cosine_similarity(sentence, document_centroid):\n",
        "#     document_vector = np.array([document_centroid])    \n",
        "#     vectorizer = TfidfVectorizer()\n",
        "#     sentence_vector = vectorizer.fit_transform([sentence])\n",
        "#     sentence_vector = convert_sparse_to_dense_general(sentence_vector, 1, 59)\n",
        "#     cosine_sim = cosine_similarity(sentence_vector, document_vector.reshape(1, -1))[0][0]\n",
        "#     return cosine_sim\n",
        "\n",
        "def calculate_sentence_scores(stemmed_text, total_sentences,  max_sentence_length):\n",
        "    sentence_scores = {}\n",
        "\n",
        "    for idx, sentence in enumerate(stemmed_text):\n",
        "        try:\n",
        "            pos_factor = calculate_pos_factor(total_sentences, idx + 1)\n",
        "            bigram_length = calculate_bigram_length(sentence)\n",
        "            trigram_length = calculate_trigram_length(sentence)\n",
        "            tf_isf = calculate_tf_isf(sentence)\n",
        "            # cosine_similarity_score = calculate_cosine_similarity(sentence, document_centroid)\n",
        "            thematic_number = calculate_thematic_number(sentence,[])\n",
        "            sentence_length_factor = calculate_sentence_length_factor(sentence, max_sentence_length)\n",
        "            numeric_tokens_ratio = calculate_numeric_tokens_ratio(sentence)\n",
        "            sentence_score = (\n",
        "                pos_factor\n",
        "                + bigram_length\n",
        "                + trigram_length\n",
        "                + tf_isf\n",
        "                # + cosine_similarity_score\n",
        "                + thematic_number\n",
        "                + sentence_length_factor\n",
        "                + numeric_tokens_ratio\n",
        "            )\n",
        "        except: \n",
        "            sentence_score = 0\n",
        "        sentence_scores[idx] = sentence_score\n",
        "    return sentence_scores\n",
        "\n",
        "def generate_summary(original_text, stemmed_text, sentence_scores, num_sentences=5):\n",
        "    sorted_sentences = sorted(sentence_scores.items(), key=lambda x: x[1], reverse=True)    \n",
        "    selected_sentences = sorted_sentences[:num_sentences]    \n",
        "    selected_sentences.sort(key=lambda x: x[0])\n",
        "    doc = original_text.split(\".\")\n",
        "    summary = ' '.join(doc[idx] for idx, _ in selected_sentences)\n",
        "    return summary\n",
        "\n",
        "def calculate_bigram_length(sentence):\n",
        "    return 0\n",
        "\n",
        "def calculate_trigram_length(sentence):\n",
        "    return 0\n",
        "\n",
        "def calculate_tf_isf(sentence):\n",
        "    return 0\n",
        "\n",
        "def calculate_sentence_length_factor(sentence, max_sentence_length):\n",
        "    return 0\n",
        "\n",
        "def calculate_numeric_tokens_ratio(sentence):\n",
        "    return 0\n",
        "\n",
        "def calculate_pos_factor(total_sentences, current_pos):\n",
        "    return 0\n",
        "\n",
        "def calculate_thematic_number(sentence, keywords):\n",
        "    return 0\n",
        "\n",
        "# Event loop\n",
        "while True:\n",
        "    event, values = window.read()\n",
        "    if event == sg.WINDOW_CLOSED or event == 'Exit':\n",
        "        break\n",
        "    elif event == 'Generate Summary' or (event == '\\r' and values['-TEXT-'] != ''):\n",
        "        # Get input values\n",
        "        marathi_text = values['-TEXT-']\n",
        "        num_sentences = int(values['-NUM_SENTENCES-'])\n",
        "        \n",
        "        # Preprocess text\n",
        "        preprocessed_text = preprocess_text(marathi_text)\n",
        "        stemmed_text = perform_marathi_stemming(marathi_text)\n",
        "        \n",
        "        # Calculate total sentences\n",
        "        total_sentences = len(stemmed_text)\n",
        "        \n",
        "        # Calculate document centroid\n",
        "        # document_centroid = calculate_centroid(stemmed_text)\n",
        "        \n",
        "        # Calculate maximum sentence length\n",
        "        max_sentence_length = max(len(sentence.split()) for sentence in stemmed_text)\n",
        "        \n",
        "        # Calculate sentence scores\n",
        "        sentence_scores = calculate_sentence_scores(stemmed_text, total_sentences,  max_sentence_length)\n",
        "        \n",
        "        # Generate summary\n",
        "        summary = generate_summary(marathi_text, stemmed_text, sentence_scores, num_sentences)\n",
        "        \n",
        "        # Update output in GUI\n",
        "        window['-OUTPUT-'].update(summary)\n",
        "    elif event == 'Reset':\n",
        "        # Clear input and output fields\n",
        "        window['-TEXT-'].update('')\n",
        "        window['-NUM_SENTENCES-'].update('')\n",
        "        window['-OUTPUT-'].update('')\n",
        "\n",
        "# Close the window\n",
        "window.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "\n",
        "# def calculate_pos_factor(total_sentences, current_pos):\n",
        "#     return (total_sentences - current_pos) / total_sentences\n",
        "\n",
        "# def calculate_bigram_token_length(sentence):\n",
        "#     # Tokenize the sentence\n",
        "#     tokens = sentence.split()\n",
        "#     # Calculate bigram token length\n",
        "#     return len(tokens) - 1\n",
        "\n",
        "# def calculate_trigram_token_length(sentence):\n",
        "#     # Tokenize the sentence\n",
        "#     tokens = sentence.split()\n",
        "#     # Calculate trigram token length\n",
        "#     return len(tokens) - 2\n",
        "\n",
        "# def calculate_tf_isf(sentence):\n",
        "#     term_freq = len(sentence.split())  # Term frequency is the number of words in the sentence\n",
        "#     sent_freq = 1  # For now, assuming each sentence appears once\n",
        "#     vocab_pos = 1  # Not sure how this should be calculated, so using a placeholder value\n",
        "#     return term_freq / (sent_freq * vocab_pos)\n",
        "\n",
        "# def calculate_cosine_similarity(sentence_vectors, centroid_vector):\n",
        "#     return np.dot(sentence_vectors, centroid_vector) / (np.linalg.norm(sentence_vectors) * np.linalg.norm(centroid_vector))\n",
        "\n",
        "# def calculate_thematic_number(sentence, total_keywords):\n",
        "#     keywords_in_sentence = len([word for word in sentence.split() if is_keyword(word)])  # Assuming is_keyword is a function that checks if a word is a keyword\n",
        "#     return keywords_in_sentence / total_keywords\n",
        "\n",
        "# def calculate_sentence_length_factor(sentence_length, max_sentence_length):\n",
        "#     return sentence_length / max_sentence_length\n",
        "\n",
        "# def calculate_numeric_tokens(sentence):\n",
        "#     # Tokenize the sentence\n",
        "#     tokens = sentence.split()\n",
        "#     # Check if there are tokens in the sentence\n",
        "#     if len(tokens) == 0:\n",
        "#         return 0\n",
        "#     # Calculate numeric tokens\n",
        "#     numeric_count = sum(token.isdigit() for token in tokens)\n",
        "#     return numeric_count / len(tokens)\n",
        "\n",
        "# def fuzzy_logic_score(preprocessed_text):\n",
        "#     total_sentences = len(preprocessed_text)\n",
        "#     scores = []\n",
        "\n",
        "#     for idx, sentence in enumerate(preprocessed_text, start=1):\n",
        "#         current_pos = idx\n",
        "#         pos_factor = calculate_pos_factor(total_sentences, current_pos)\n",
        "#         bigram_token_length = calculate_bigram_token_length(sentence)\n",
        "#         trigram_token_length = calculate_trigram_token_length(sentence)\n",
        "#         tf_isf = calculate_tf_isf(sentence)\n",
        "#         cosine_similarity = calculate_cosine_similarity(sentence_data['sentence_vector'], sentence_data['centroid_vector'])\n",
        "#         thematic_number = calculate_thematic_number(sentence, total_keywords)  # Assuming total_keywords is available\n",
        "#         sentence_length_factor = calculate_sentence_length_factor(len(sentence), max_sentence_length)  # Assuming max_sentence_length is available\n",
        "#         numeric_tokens = calculate_numeric_tokens(sentence)\n",
        "        \n",
        "#         # Apply fuzzy logic rules and return the score\n",
        "#         if pos_factor >= 0.5 and sentence_length_factor >= 0.5 and thematic_number >= 0.5 and numeric_tokens >= 0.5:\n",
        "#             scores.append('good')\n",
        "#         elif pos_factor <= 0.2 and sentence_length_factor <= 0.2 and numeric_tokens <= 0.2:\n",
        "#             scores.append('bad')\n",
        "#         elif thematic_number <= 0.2:\n",
        "#             scores.append('bad')\n",
        "#         elif cosine_similarity >= 0.5:\n",
        "#             scores.append('good')\n",
        "#         elif bigram_token_length >= 0.5 and trigram_token_length >= 0.5 and numeric_tokens <= 0.5:\n",
        "#             scores.append('average')\n",
        "#         else:\n",
        "#             scores.append('average')\n",
        "\n",
        "#     return scores\n",
        "\n",
        "# # Example usage:\n",
        "# preprocessed_text = perform_marathi_stemming(\"मी एका विद्यार्थी आहे. माझं आवडतं खेळ फुटबॉल आहे.\")\n",
        "\n",
        "# scores = fuzzy_logic_score(preprocessed_text)\n",
        "# print(scores)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def perform_marathi_stemming(text):\n",
        "#     doc = text.split(\".\")\n",
        "#     suffixes = {\n",
        "#         1: [u\"ो\", u\"े\", u\"ू\", u\"ु\", u\"ी\", u\"ि\", u\"ा\", u\"च\"],\n",
        "#         2: [u\"चा\", u\"चे\", u\"ने\", u\"नी\", u\"ना\", u\"ते\", u\"ीं\", u\"तील\", u\"ात\", u\"ाँ\", u\"ां\", u\"ों\", u\"ें\", u\"तच\", u\"ता\", u\"ही\",\n",
        "#             u\"ले\"],\n",
        "#         3: [u\"ाचा\", u\"ाचे\", u\"तील\", u\"ानी\", u\"ाने\", u\"ाना\", u\"ाते\", u\"ाती\", u\"ाता\", u\"तीं\", u\"तून\", u\"तील\", u\"तही\", u\"तपण\",\n",
        "#             u\"कडे\", u\"ातच\", u\"हून\", u\"पणे\", u\"ाही\", u\"ाले\"],\n",
        "#         4: [u\"मधले\", u\"ातील\", u\"च्या\", u\"न्या\", u\"ऱ्या\", u\"ख्या\", u\"वर\", u\"साठी\", u\"ातून\", u\"कडून\", u\"मुळे\", u\"वरून\",\n",
        "#             u\"ातील\", u\"नीही\", u\"ातही\", u\"ातपण\", u\"ाकडे\", u\"पाशी\", u\"ाहून\", u\"ापणे\", u\"मधला\"],\n",
        "#         5: [u\"ामधले\", u\"ाच्या\", u\"ान्या\", u\"ाऱ्या\", u\"ाख्या\", u\"ावर\", u\"ासाठी\", u\"पासून\", u\"ाकडून\", u\"ामुळे\", u\"ावरून\",\n",
        "#             u\"कडेही\", u\"ानीही\", u\"ापाशी\", u\"ामधला\", u\"मध्ये\"],\n",
        "#         6: [u\"पर्यंत\", u\"ापासून\", u\"ाकडेही\", u\"पूर्वक\", u\"लेल्या\", u\"ामध्ये\"],\n",
        "#         7: [u\"ापर्यंत\", u\"प्रमाणे\", u\"तसुद्धा\", u\"ापूर्वक\", u\"ालेल्या\"],\n",
        "#         8: [u\"ाप्रमाणे\", u\"ातसुद्धा\"],\n",
        "#     }\n",
        "#     preprocessed_text = \"\"\n",
        "#     print(doc)\n",
        "#     for each in doc:\n",
        "#         tokens = each.split(' ')\n",
        "#         cleaned_tokens = []\n",
        "#         for tok in tokens:\n",
        "#             if '-' in tok:\n",
        "#                 subtokens = tok.split('-')\n",
        "#                 cleaned_tokens.extend(subtokens)\n",
        "#             else:\n",
        "#                 cleaned_tokens.append(tok.strip())\n",
        "\n",
        "#         stems = []\n",
        "#         for word in cleaned_tokens:\n",
        "#             for i in range(8, 0, -1):\n",
        "#                 if len(word) > i + 1:\n",
        "#                     for suf in suffixes[i]:\n",
        "#                         if word.endswith(suf):\n",
        "#                             word = word[:-i]\n",
        "#             if word:\n",
        "#                 stems.append(word)\n",
        "#         preprocessed_text += ' '.join(stems)\n",
        "#         preprocessed_text += \".\"\n",
        "#     return preprocessed_text\n",
        "\n",
        "\n",
        "# # Example usage:\n",
        "# input_text = \"\"\"एका गावात एक छोटा सुंदर मुलगा होता. त्याच्या नावाचं 'राहुल' होतं. राहुलने प्रत्येक दिवस शाळेत आणि घरीचं खेळायला मनापासून वाढवलं. त्याच्या आईबाबांनी त्याला प्रत्येक वेळी सांगितलं, \"पुढचं शिका, पुढचं उभा आणि प्रत्येक क्षण आनंदाने जगा.\" \n",
        "\n",
        "# एका दिवशी, राहुलने अपन्या मित्रांसोबत एका आग्रहाच्या खेळाचं स्वागत केलं. त्याच्या मनात वाटत होतं, \"माझं स्वप्न याचं सफर कसं सुरू होतं आणि कसं आनंदाने संपतं, ते सर्वांसाठी आणि माझ्या आईबाबांसाठी कसं उपयोगी होतं.\"\n",
        "\n",
        "# त्याच्या आग्रहाच्या खेळाचं सुरू होतं आणि राहुल आणि त्याच्या मित्रांनी खूप आनंदाने खेळलं. त्यांना वेळ अद्याप अधिक मजा केला. राहुल आणि त्याच्या मित्रांनी साथीत खेळून खूप आनंदाने वेळ व्यतीत केलं.\n",
        "\n",
        "# खेळाच्या शेवटी, राहुलने समजलं की, सफर महत्त्वाचं असतं. त्याचं उद्दिष्टं नक्कीपणा प्राप्त करणं आणि त्याचं स्वप्न पूर्ण करणं हे महत्त्वाचं आहे. त्याने निरंतर यशस्वीपणे काम केलं आणि आपल्या स्वप्नांचं सफर पूर्ण केलं.\n",
        "\n",
        "# अखेर, त्याचं उद्दिष्ट साधलं आणि त्याचं स्वप्न साकार झालं. त्याचं परिश्रम आणि आत्मविश्वास ने त्याला प्रत्येकाला आणि समुदायाला प्रेरित केलं. राहुल आणि त्याचे मित्र एकत्र येऊन एकाच नात्याने सामाजिक सेवेत सहभागी झाले आणि स्वप्न साकार झाले.\n",
        "\n",
        "# सद्यस्थितीत, राहुलने आपलं स्वप्न पूर्ण केलं, आणि त्याने प्रत्येक क्षण आनंदाने जगा.\"\"\"\n",
        "# output_text = perform_marathi_stemming(input_text)\n",
        "# print(output_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def summarize_marathi_text(text, num_sentences, sentence_priorities=None):\n",
        "#   \"\"\"\n",
        "#   This function summarizes a Marathi text document with priority consideration (optional).\n",
        "\n",
        "#   Args:\n",
        "#       text: The Marathi text as a string.\n",
        "#       num_sentences: The desired number of sentences in the summary.\n",
        "#       sentence_priorities: A list containing priority values for each sentence (same order as sentences). Defaults to None (no priority consideration).\n",
        "\n",
        "#   Returns:\n",
        "#       A string containing the summarized text, or an informative message if there are fewer sentences than requested.\n",
        "#   \"\"\"\n",
        "#   # Language detection and validation (same as before)\n",
        "\n",
        "#   # Sentence segmentation\n",
        "#   tokenizer = PunktSentenceTokenizer()\n",
        "#   sentences = tokenizer.tokenize(text)\n",
        "\n",
        "#   # Combine sentences and priorities (if provided)\n",
        "#   if sentence_priorities is not None:\n",
        "#       if len(sentences) != len(sentence_priorities):\n",
        "#           raise ValueError(\"Number of sentences and priorities must match.\")\n",
        "#       sentence_data = list(zip(sentences, sentence_priorities))\n",
        "#   else:\n",
        "#       sentence_data = list(enumerate(sentences))  # Enumerate for indexing\n",
        "\n",
        "#   # Handle cases with fewer sentences than requested\n",
        "#   if len(sentence_data) < num_sentences:\n",
        "#       available_sentences = len(sentence_data)\n",
        "#       print(f\"The text has only {available_sentences} sentences. Returning the available sentences as summary.\")\n",
        "#       summary_data = sentence_data[:available_sentences]\n",
        "#   else:\n",
        "#       # No priority consideration (use original order)\n",
        "#       summary_data = sentence_data[:num_sentences]\n",
        "\n",
        "#   # Extract sentences while maintaining order\n",
        "#   summary = [sentence for index, sentence in summary_data]\n",
        "\n",
        "#   return \" \".join(summary)\n",
        "\n",
        "\n",
        "# def main():\n",
        "#     nltk.download('punkt')\n",
        "\n",
        "#     layout = [\n",
        "#         [sg.Text(\"Enter your Marathi text:\", font=(\"Arial\", 12, \"bold\"))],\n",
        "#         [sg.Multiline(key=\"marathi_text\", size=(800, 12), font=(\"Arial\", 12))],  # Input Box\n",
        "#         [sg.Text(\"Number of sentences for summary:\", font=(\"Arial\", 12, \"bold\"))],\n",
        "#         [sg.Spin([i for i in range(1, 11)], initial_value=2, key=\"num_sentences\")],\n",
        "#         [sg.Text(\"Sentence Priorities (separated by spaces):\", font=(\"Arial\", 12, \"bold\"))],\n",
        "#         [sg.InputText(\"\", key=\"priority_input\", font=(\"Arial\", 12))],  # Priority input field\n",
        "#         [sg.Button(\"Summarize\"), sg.Exit(), sg.Button(\"Reset\")],\n",
        "#         [sg.Output(size=(800, 12), key=\"summary_output\", font=(\"Arial\", 12))]  # Use Output for multi-line display\n",
        "#     ]\n",
        "\n",
        "#     window = sg.Window(\"Marathi Text Summarizer\", layout, size=(1000, 600))\n",
        "\n",
        "#     while True:\n",
        "#         event, values = window.read()\n",
        "#         if event in (sg.WIN_CLOSED, 'Exit'):\n",
        "#             break\n",
        "#         elif event == 'Summarize':\n",
        "#             marathi_text = values[\"marathi_text\"]\n",
        "#             try:\n",
        "#                 num_sentences = int(values[\"num_sentences\"])\n",
        "#                 # Get sentence priorities from user input\n",
        "#                 sentence_priorities = [int(p) for p in values[\"priority_input\"].split()]  # Split user input\n",
        "#                 if len(sentence_priorities) != len(marathi_text.split(\". \")):  # Validate priority count\n",
        "#                     raise ValueError(\"Number of priorities must match the number of sentences.\")\n",
        "\n",
        "#                 summary = summarize_marathi_text(marathi_text, num_sentences, sentence_priorities)\n",
        "#                 window[\"summary_output\"].update(summary)\n",
        "#             except ValueError:\n",
        "#                 # Handle invalid number of sentences or priorities\n",
        "#                 window[\"summary_output\"].update(\"Invalid input. Please enter integers for number of sentences and priorities (separated by spaces).\")\n",
        "#             except Exception as e:\n",
        "#                 # Broader exception handling (optional)\n",
        "#                 window[\"summary_output\"].update(f\"An error occurred: {str(e)}\")\n",
        "#         elif event == 'Reset':\n",
        "#             # Clear input and output, ready for new text\n",
        "#             window[\"summary_output\"].update(\"\")\n",
        "#             window[\"marathi_text\"]\n",
        "\n",
        "#     if event == 'Summarize':\n",
        "#         marathi_text = values[\"marathi_text\"]\n",
        "#         try:\n",
        "#             num_sentences = int(values[\"num_sentences\"])\n",
        "#             # Get sentence priorities from user input (modify as needed)\n",
        "#             sentence_priorities = [int(p) for p in values[\"priority_input\"].split()]  # Example: split user input\n",
        "\n",
        "#             summary = summarize_marathi_text(marathi_text, num_sentences, sentence_priorities)\n",
        "#             window[\"summary_output\"].update(summary)\n",
        "#         except ValueError:\n",
        "#             # Handle invalid number of sentences or priorities\n",
        "#             window[\"summary_output\"].update(\"Invalid input. Please enter integers for number of sentences and priorities (separated by spaces).\")\n",
        "#         except Exception as e:\n",
        "#             # Broader exception handling (optional)\n",
        "#             window[\"summary_output\"].update(f\"An error occurred: {str(e)}\")\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Function 1 paragraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "WaivnLvlQ7Vn"
      },
      "outputs": [],
      "source": [
        "# def summarize_marathi_text(text, num_sentences):\n",
        "#   # Language detection and validation\n",
        "#   detected_language = detect(text)\n",
        "#   if detected_language != 'mr':  # Marathi language code is 'mr'\n",
        "#     print(\"Please enter text in Marathi language.\")\n",
        "#     return None  # Indicate failure or handle error message display\n",
        "\n",
        "#   # Sentence segmentation\n",
        "#   tokenizer = PunktSentenceTokenizer()\n",
        "#   sentences = tokenizer.tokenize(text)\n",
        "\n",
        "#   # Sentence scoring (basic approach)\n",
        "#   sentence_scores = []\n",
        "#   for sentence in sentences:\n",
        "#       score = 0  # Initialize score for each sentence\n",
        "\n",
        "#       # Sentence length score (favor moderate length)\n",
        "#       avg_length = sum(len(s) for s in sentences) / len(sentences)\n",
        "#       length_diff = abs(len(sentence) - avg_length)\n",
        "#       score += 0.1 - (length_diff * 0.005)  # Penalty for extreme lengths\n",
        "\n",
        "#       sentence_scores.append(score)\n",
        "      \n",
        "#   # Sort sentences with scores\n",
        "#   sorted_sentences = sorted(zip(sentences, sentence_scores), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "#   # Handle cases with fewer sentences than requested\n",
        "#   if len(sorted_sentences) < num_sentences:\n",
        "#       available_sentences = len(sorted_sentences)\n",
        "#       print(f\"The text has only {available_sentences} sentences. Returning the available sentences as summary.\")\n",
        "#       summary = [sentence for sentence, _ in sorted_sentences[:available_sentences]]  # Get only available sentences\n",
        "#   else:\n",
        "#       # Select top sentences as before\n",
        "#       summary = [sentence for sentence, _ in sorted_sentences[:num_sentences]]\n",
        "\n",
        "#   return \" \".join(summary)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Function 2 Sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from nltk.tokenize import PunktSentenceTokenizer, word_tokenize\n",
        "\n",
        "\n",
        "# def summarize_marathi_text(text, num_sentences):\n",
        "# #   # Language detection and validation\n",
        "#   detected_language = detect(text)\n",
        "#   if detected_language != 'mr':  # Marathi language code is 'mr'\n",
        "#     print(\"Please enter text in Marathi language.\")\n",
        "#     return None  # Indicate failure or handle error message display\n",
        "  \n",
        "#   # Sentence segmentation\n",
        "#   tokenizer = PunktSentenceTokenizer()\n",
        "#   sentences = tokenizer.tokenize(text)\n",
        "\n",
        "#   # Basic sentence scoring approach (modify as needed)\n",
        "#   sentence_scores = []\n",
        "#   for sentence in sentences:\n",
        "#       score = 0  # Initialize score for each sentence\n",
        "\n",
        "#       # Sentence length score (favor moderate length)\n",
        "#       avg_length = sum(len(s) for s in sentences) / len(sentences)\n",
        "#       length_diff = abs(len(sentence) - avg_length)\n",
        "#       score += 0.1 - (length_diff * 0.005)  # Penalty for extreme lengths\n",
        "\n",
        "#       # Add more scoring criteria here (e.g., keyword frequency, position)\n",
        "\n",
        "#       sentence_scores.append(score)\n",
        "\n",
        "#   # Sort sentences with scores (descending order)\n",
        "#   sorted_sentences = sorted(zip(sentences, sentence_scores), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "#   # Extract top-ranked sentences\n",
        "#   top_sentences = [sentence for sentence, _ in sorted_sentences[:num_sentences]]\n",
        "\n",
        "#   # Tokenize words in each top-ranked sentence\n",
        "#   tokenized_sentences = []\n",
        "#   for sentence in top_sentences:\n",
        "#       tokenized_words = word_tokenize(sentence)\n",
        "#       tokenized_sentences.append(tokenized_words)\n",
        "\n",
        "#   # Return list of tokenized words from top ranked sentences\n",
        "#   return tokenized_sentences\n",
        "\n",
        "\n",
        "# def main():\n",
        "#   nltk.download('punkt')\n",
        "\n",
        "#   layout = [\n",
        "#       [sg.Text(\"Enter your Marathi text:\", font=(\"Arial\", 12, \"bold\"))],\n",
        "#       [sg.Multiline(key=\"marathi_text\", size=(800, 12), font=(\"Arial\", 12))],  # Input Box\n",
        "#       [sg.Text(\"Number of sentences for summary:\", font=(\"Arial\", 12, \"bold\"))],\n",
        "#       [sg.Spin([i for i in range(1, 11)], initial_value=2, key=\"num_sentences\")],\n",
        "#       [sg.Button(\"Summarize\"), sg.Exit(), sg.Button(\"Reset\")],\n",
        "#       [sg.Output(size=(800, 12), key=\"summary_output\", font=(\"Arial\", 12))]  # Use Output for multi-line display\n",
        "#   ]\n",
        "\n",
        "#   window = sg.Window(\"Marathi Text Summarizer\", layout, size=(1000, 600))\n",
        "\n",
        "#   while True:\n",
        "#         event, values = window.read()\n",
        "#         if event in (sg.WIN_CLOSED, 'Exit'):\n",
        "#           break    \n",
        "\n",
        "#         elif event == 'Summarize':\n",
        "#             marathi_text = values[\"marathi_text\"]\n",
        "#             try:\n",
        "#                 num_sentences = int(values[\"num_sentences\"])\n",
        "\n",
        "#                 tokenized_summary = summarize_marathi_text(marathi_text, num_sentences)\n",
        "\n",
        "#                 # Example: Print or display the tokenized summary (modify as needed)\n",
        "#                 for sentence in tokenized_summary:\n",
        "#                     print(\" \".join(sentence))\n",
        "\n",
        "#             except ValueError:\n",
        "#                 # Handle invalid number of sentences\n",
        "#                 window[\"summary_output\"].update(\"Invalid input. Please enter an integer for the number of sentences.\")\n",
        "#             except Exception as e:\n",
        "#                 # Broader exception handling (optional)\n",
        "#                 window[\"summary_output\"].update(f\"An error occurred: {str(e)}\")\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Function 3 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def summarize_marathi_text(text, num_sentences, keywords=None):\n",
        "\n",
        "# # Language detection and validation\n",
        "#   detected_language = detect(text)\n",
        "#   if detected_language != 'mr':  # Marathi language code is 'mr'\n",
        "#     print(\"Please enter text in Marathi language.\")\n",
        "#     return None  # Indicate failure or handle error message display\n",
        "  \n",
        "#   # Sentence segmentation\n",
        "#   tokenizer = PunktSentenceTokenizer()\n",
        "#   sentences = tokenizer.tokenize(text)\n",
        "\n",
        "#   # Keyword frequency calculation (if keywords provided)\n",
        "#   if keywords:\n",
        "#       word_counts = Counter(word_tokenize(text.lower()))  # Lowercase for case-insensitive matching\n",
        "#       keyword_scores = {word: word_counts[word] for word in keywords}  # Count occurrences of each keyword\n",
        "#   else:\n",
        "#       keyword_scores = {}  # Empty dictionary if no keywords provided\n",
        "\n",
        "#   # Sentence scoring approach (consider length and keyword frequency)\n",
        "#   sentence_scores = []\n",
        "#   for i, sentence in sentences:\n",
        "#       score = 0  # Initialize score for each sentence\n",
        "\n",
        "#       # Sentence length score (favor moderate length)\n",
        "#       avg_length = sum(len(s) for s in sentences) / len(sentences)\n",
        "#       length_diff = abs(len(sentence) - avg_length)\n",
        "#       score += 0.1 - (length_diff * 0.005)  # Penalty for extreme lengths\n",
        "\n",
        "#       # Keyword frequency score (if keywords provided)\n",
        "#       for word, count in keyword_scores.items():\n",
        "#           if word in sentence.lower():  # Lowercase for case-insensitive matching\n",
        "#               score += count * 0.05  # Adjust weight as needed\n",
        "      \n",
        "#       # Positional weight\n",
        "#       position_weight = (len(sentences) - i) / len(sentences)\n",
        "#       score += position_weight * 0.2\n",
        "      \n",
        "#       # Named entity recognition (example: prioritize sentences with people)\n",
        "#       entities = nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sentence)))\n",
        "#       for entity in entities:\n",
        "#           if type(entity) == nltk.Tree and entity.label() == 'PERSON':\n",
        "#               score += 0.1\n",
        "\n",
        "#       sentence_scores.append(score)\n",
        "\n",
        "#   # Sort sentences with scores (descending order)\n",
        "#   sorted_sentences = sorted(zip(sentences, sentence_scores), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "#   # Extract top-ranked sentences\n",
        "#   top_sentences = [sentence for sentence, _ in sorted_sentences[:num_sentences]]\n",
        "\n",
        "#   # Tokenize words in each top-ranked sentence\n",
        "#   tokenized_sentences = []\n",
        "#   for sentence in top_sentences:\n",
        "#       tokenized_words = word_tokenize(sentence)\n",
        "#       tokenized_sentences.append(tokenized_words)\n",
        "\n",
        "#   # Return list of tokenized words from top ranked sentences\n",
        "#   return tokenized_sentences\n",
        "\n",
        "\n",
        "# def main():\n",
        "\n",
        "#     nltk.download('punkt')\n",
        "\n",
        "#     layout = [\n",
        "#         [sg.Text(\"Enter your Marathi text:\", font=(\"Arial\", 12, \"bold\"))],\n",
        "#         [sg.Multiline(key=\"marathi_text\", size=(800, 12), font=(\"Arial\", 12))],  # Input Box\n",
        "#         [sg.Text(\"Number of sentences for summary:\", font=(\"Arial\", 12, \"bold\"))],\n",
        "#         [sg.Spin([i for i in range(1, 11)], initial_value=2, key=\"num_sentences\")],\n",
        "#         [sg.Button(\"Summarize\"), sg.Exit(), sg.Button(\"Reset\")],\n",
        "#         [sg.Output(size=(800, 12), key=\"summary_output\", font=(\"Arial\", 12))]  # Use Output for multi-line display\n",
        "#     ]\n",
        "\n",
        "#     window = sg.Window(\"Marathi Text Summarizer\", layout, size=(1000, 600))\n",
        "\n",
        "#     while True:\n",
        "#             event, values = window.read()\n",
        "#             if event in (sg.WIN_CLOSED, 'Exit'):\n",
        "#                 break\n",
        "\n",
        "#             elif event == 'Summarize':\n",
        "#                 marathi_text = values[\"marathi_text\"]\n",
        "#                 try:\n",
        "#                     num_sentences = int(values[\"num_sentences\"])\n",
        "#                     keywords = [str(keyword).lower() for keyword in values.get(\"keywords\", [])]  # Get optional keywords (lowercase)\n",
        "\n",
        "#                     tokenized_summary = summarize_marathi_text(marathi_text, num_sentences, keywords)\n",
        "\n",
        "#                     # Example: Print or display the tokenized summary (modify as needed)\n",
        "#                     for sentence in tokenized_summary:\n",
        "#                         print(\" \".join(sentence))\n",
        "\n",
        "#                 except ValueError:\n",
        "#                     # Handle invalid number of sentences\n",
        "#                     window[\"summary_output\"].update(\"Invalid input. Please enter integers for number of sentences and keywords (optional).\")\n",
        "#                 except Exception as e:\n",
        "#                     # Broader exception handling (optional)\n",
        "#                     window[\"summary_output\"].update(f\"An error occurred: {str(e)}\")\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GUI Display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def main():\n",
        "#   nltk.download('punkt')\n",
        "\n",
        "#   layout = [\n",
        "#       [sg.Text(\"Enter your Marathi text:\", font=(\"Arial\", 12, \"bold\"))],\n",
        "#       [sg.Multiline(key=\"marathi_text\", size=(800, 12), font=(\"Arial\", 12))],  # Input Box\n",
        "#       [sg.Text(\"Number of sentences for summary:\", font=(\"Arial\", 12, \"bold\"))],\n",
        "#       [sg.Spin([i for i in range(1, 11)], initial_value=5, key=\"num_sentences\")],\n",
        "#       [sg.Button(\"Summarize\"), sg.Exit(), sg.Button(\"Reset\")],\n",
        "#       [sg.Output(size=(800, 12), key=\"summary_output\", font=(\"Arial\", 12))]  # Use Output for multi-line display\n",
        "#   ]\n",
        "\n",
        "#   window = sg.Window(\"Marathi Text Summarizer\", layout, size=(1000, 600))\n",
        "\n",
        "#   while True:\n",
        "#       event, values = window.read()\n",
        "#       if event in (sg.WIN_CLOSED, 'Exit'):\n",
        "#           break\n",
        "#       elif event == 'Summarize':\n",
        "#           marathi_text = values[\"marathi_text\"]\n",
        "#           try:\n",
        "#               num_sentences = int(values[\"num_sentences\"])\n",
        "#               summary = summarize_marathi_text(marathi_text, num_sentences)\n",
        "#               window[\"summary_output\"].update(summary)  # Display summary\n",
        "#           except ValueError:\n",
        "#               # Handle invalid number of sentences\n",
        "#               window[\"summary_output\"].update(\"Invalid number of sentences. Please enter an integer between 1 and 10.\")\n",
        "#           except Exception as e:  # Broader exception handling (optional)\n",
        "#               window[\"summary_output\"].update(f\"An error occurred: {str(e)}\")\n",
        "#       elif event == 'Reset':\n",
        "#           # Clear input and output, ready for new text\n",
        "#           window[\"summary_output\"].update(\"\")\n",
        "#           window[\"marathi_text\"].update(\"\")\n",
        "\n",
        "#   window.close()  # Also clear input box on exit\n",
        "#   window[\"marathi_text\"].update(\"\")  # Optional: Clear input box on exit\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#   main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWNmORBPrugg"
      },
      "source": [
        "# Method 1 : direct input of text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "OWNmORBPrugg"
      },
      "outputs": [],
      "source": [
        "# marathi_text = \"\"\"कमळ हे फूल मंद सुवासिक व आकर्षक असल्यामुळे ते सर्वाना आवडते. पांढरा, लाल ,गुलाबी, काळपट जांभळा असे कमळाचे विविध रंग असतात. कमळाची पाने मोठी व लेबगोल आकाराची असतात. कमळाच्या फुलाच्या देठांमध्ये हवेच्या पोकळया असतात. देळाची लांबी जास्त असते, दंठाचा रंग पाढरट- हिरवा असतो, देठाच्या पोकळीत हवा व पाणी भरल्याने हे देठ पाण्यावर ताठ उभे राहतात. कमळाच्या पानावर मेणासारखा पातळ थर असतो.त्यामुळे पाण्यात राहूनही ही पाने कुजत नाहीत. सरोवरात उमलणारी कमळे, ब्रह्मकमळ, कृष्णकमळ असे या फुलांचे प्रकार आहेत. ही फुले सरोवरात आणि तलावात उमलतात. ब्रम्हमकमळाचे रोप किंवा बी नसते. या फुलझाडांचे पान कुंडीत किंवा जमिनीत लावतात. पानाला पाने फुटत याचे राप तयार होते. ही झाडे साधारणत: एक ते दीड मीटर उंच असतात. यांना वर्षातून एकदाच फुले येतात. ब्रम्हकमळाचे फुल रात्री बारा वाजता उमलते. या झाडासमोर आपण बसून राहिलो तरी हे फुल उमललेले आपल्याला समजत नाही. कृष्णकमळाचा वेल असतो. वेलीला फुले आल्यावर हा वेल खूपच छान दिसतो.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "mh6gopMBSOMF"
      },
      "outputs": [],
      "source": [
        "# marathi_text = \"\"\"हेज्यायची कटकट करवादत तो भेलकांडत उठला. बंगालीकडचा हा नवा स्टॉक जरा जास्त पावरबाज निघाला होता त्याच्यासाठी. तरी बंगाली सांगत होता, बॉडी बारीक आहे तर जरा कमी दम मार म्हणून. पण बॉडीने काय होतंय भेंडी.. अर्ध्या शहरात आपली हवा आहे, कोन माय का लाल पण आपल्या नादाला लागत नाही. चुकून कोणी तसं वाटलं तरी आपला कोयता आणि तो... साल पण घरच्याना लै प्रॉब्लेम. पूर्वी महिन्यातून एकदा अंडी आणि पाव्हने आल्यावर चिकन खाणारे हे, आता रोज बोट्या हाणतात तेव्हा नाय दिसत का हा पैसा कुटून आला. जाउंदे भेंडी.. सकाळ सकाळ काय भोसडा उदास करायचा.. मनातल्या मनात हे चालू असताना मोन्याने चूळ भरली, अंगणात आला तर सूर्य डोक्यावर.. 10 पावलावर टपरीवर जाऊन त्याने सिगरेट पेटवली आणि टपरीवाल्याला एक टपली हाणली. आज दिवस कसा सत्कारणी लावायचा याचा विचार चालू असताना त्याला परवाची संध्याकाळ आठवली.. पलीकडच्या गल्लीत सुरू असलेल्या क्लाससमोरची ती बोळ.. क्लासमधून बाहेर पडलेली ती साधीशी पण फटाकडी पोरगी, आणि त्याने केलेला तो प्रकार.. आठवून पुन्हा गुदगुल्या होत होत्या त्याला. आज पण तिकडे जायचं ठरवून तो मोकळा झाला. आज काय विषय? म्हणत तो त्यांच्या नेहमीच्या अड्ड्यावर बसला. खरं तर त्याला कंटाळा आला होता.. मागच्या 302 मधून वाचण्यासाठी जोशींभाऊनी जरा सुमडीत राहायला सांगितलं होतं म्हणून.. नाहीतर सलग 2 आठवडे शहरात राहण्याची ही वेळच आली नसती. जोशींभाऊनी सांगितलं म्हणजे थांबायला हवं.. जोशी नसता तर आपले हाल कुत्र्याने खाल्ले नसते याची त्याला जाणीव होती. काय नाय भाई, काल तो चायनिजवाला मला म्हणतो कसा, शेठ 15 दिवस झाले रोज खाऊन जाताय, जरा बिलाचे पैसे बघा, पूर्ण नको, पण अर्धे तरी जमवा शेठ.. त्याला म्हणलं मोन्याभाईसाठी नेतोय चायनीज मग..? मग काय भाई, त्याची टिरटीर चालूच.. दिली मग एक साटकन ठेवून, तर त्याने माझी कॉलर धरली भाई, म्हणाला मोन्याभाई आहे म्हणून अर्धे मागतोय.. त्याला सांगून आलोय, आज रात्री 9 वाजता तुझा हिशोब करायला मोन्याभाई सोत्ता येणार.. अच्छा.. हे लक्षण काय ठीक नव्हतं.. आपली हवा कमी होतेय हे मोन्याला लक्षात आलं. तो उठला, आपल्या गाडीला सेल मारून निघाला, त्याच्यामागे त्याचे दोनचार पंटर.. गुरू थेटरात एक पिच्चर पाहून ते बंगालीच्या अड्ड्यावर गेले.. चार आठ दम मारले, आणि सोबत दारु.. जसे 8 वाजले तसे मोन्याला क्लास आठवला. पण ती पोरगी आलीच नव्हती. मग दिसेल तिला जरा चिडीमारी करून शेवटी तो चायनीज गाडीवर पोचला.. तिथे सात आठ गिऱ्हाईक. गर्दी बघून त्याने आवाज मोठा करून चायनीजवाल्याला शिव्या देणं सुरू केलं आणि धावल्यासारखा त्याच्या अंगावर गेला.. जाताना त्याने एकदोघांना धक्का मारला.. की त्याला कुणी धक्का मारला? विचार करायला वेळ नव्हता कारण त्याला आता चायनिजवाल्याला राउंडमध्ये घ्यायचं होतं.. साला आपल्याला पैसे मागतो भेंडी.. गांजाची तार चांगलीच डोक्यात गेली होती.. त्याला ती लाल गाडी हलताना दिसत होती.. आज जरा जास्त स्ट्रॉंग झालाय कार्यक्रम.. त्याच्या लक्षात आलं.. पण पण.. विचार करता करता तो भेलकांडून जाऊन भिजवलेल्या मंचुरीयनच्या टोपल्यात पडला.. त्याचे पंटर त्याला उचलायचा प्रयत्न करत होते.. पण मोन्याला स्वस्थ होताच येत नव्हतं.. खूप तडफड करत त्याचं सगळं शरीर एकाजागी गोळा झालं.. त्याची अवस्था बघुन पंटर पळून गेले.. शेवटी चायनीजवाल्यानेच त्याला सिव्हिलला दाखल केलं.. पण.. उशीर झाला होता.. दुसऱ्या दिवशी पेपरात, नशेचा, दारूचा अतिरेक वगैरे मथळ्यात त्याची बातमी आली.. जोशीने सूत्रं फिरवून त्याचा आपल्याशी असलेला संबंध लपवला होता.. व्हिल हॉस्पिटल: मोन्याच्या मृत्यूमध्ये पोलिसांनी लक्ष देण्यासारखं फार नसलं तरी डॉक्टर शिंदे मात्र अस्वस्थ होते. मोन्याच्या रक्तात त्यांना एक अनोळखी संयुगाचे ट्रेसेस सापडले होते. गांजा, दारू अतिसेवनाच्या केसेस त्यांनी भरपूर पाहिल्या असल्या तरी ही केस काहीतरी वेगळी होती.. मोन्याच्या यातना त्यांनी पाहिल्या होत्या.. त्याच्या प्रायव्हेट पार्टला झालेला अतिशय जास्त रक्तपुरवठा, आणि शिवाय, एक अनोळखी संयुग जे ट्रेस करण्यापूर्वी विघटित झालं असावं.. दंडावर असलेल्या छोट्या छोट्या puncture wounds त्यांनी पाहिल्या, पण मोन्याच्या ड्रग abuse history त्यांना माहीत होती. शंका नको म्हणून शिंदेंच्या सूचनेनुसार पोलिसांनी गुपचूप जाऊन बंगालीकडून आणलेला गांजा शिंदेंनी चेक केला होता, पण त्यात प्राणघातक असं काही नव्हतं. पोलिसांच्या सूचनेनुसार रिपोर्टमध्ये त्यांनी गांजा दारू वगैरे कारणं दिली असली तरी, ही केस त्यांच्या डोक्यात फिट्ट होती.. अशी केस त्यांनी आधी पाहिल्याचं त्यांना अंधुक आठवत होतं, पण केव्हा कुठे ते जाम डोक्याबाहेर गेलं होतं.. मोन्याच्या घरात दुःखाचं वातावरण म्हटलं तर होतं, म्हटलं तर नव्हतं.. एक पीडा गेली असं एकीकडे वाटत होतं, तर पैश्याचा ओघ थांबला असं दुसरीकडे.. त्या घरात जरी संमिश्र भावना असल्या, तरी कॉलनीत, व्यापारी वर्गात आणि इतर सगळ्यांना आनंद झाला होता. खास करून त्या मुलीच्या घरात...\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "ThDxrM0ISOIY"
      },
      "outputs": [],
      "source": [
        "# marathi_text = \"\"\"विस्तीर्ण पसरलेलं जंगल, जंगलातच उगम पावलेली आणि गावाला वेढा देणारी, आजूबाजूच्या डोंगरांना हिरवाई देणारी वाघई नदी, एका बाजूला जंगल तर बाकी तीन बाजूंना नदी आणि डोंगरदऱ्यांनी वेढलेलं टुमदार गाव- वाघदरा. पूर्वी मुबलक असणाऱ्या वाघांच्या संख्येमुळे हे नाव या नदीला आणि गावाला लाभलं होतं. गावात एक प्राथमिक शाळा, एक पोस्टाची पेटी. बाकी सारे व्यवहार करायला गावकऱ्यांना २० किमी लांब जावं लागत असे. दादाराव पाटील आल्यापासून तशी गरज जास्त उरली नव्हती हेही खरं. फोन वरून बरच कामे होत, शिवाय वाड्यावर कॉम्प्युटरवर होण्यासारखी सारी सरकारी कामे होऊन जात होती. वाड्यावर म्हणजे दादाराव पाटलांच्या वाड्यावर..\n",
        "# जंगलाला लागून असलेला हा वाडा म्हणजे एक कोडं होतं. वाड्याचा पसारा मोठा म्हणजे जवळपास एकर भर.. नदी आणि जंगलाच्या आडोशाला जागा पाहून चाऱ्ही बाजूला पुरुषभर उंचीच्या दगडी भिंती जंगलाच्या बाजूला बांधलेला दोन मजली चौसोपी टुमदार वाडा. त्याच्यापुढं दगडी कुंपणाच्या बरोबरीनेच बांधलेला मोठाच्या मोठा गोठा, तबेला, कुत्र्यांसाठीची जाळीदार खोली. आणि अजून ८ खोल्या.. वाड्याच्या मुख्य दारापाशी दोन्ही बाजूला बैठकीच्या खोल्या. बाहेरून येणार जाणार सारे लोक आधी इथे थांबत आणि प्राथमिक चर्चा इथे होई, आणि मगच पुढं एन्ट्री. अर्थात गावाच्या कोणत्याही रहिवाश्याला वाड्यात बिनधोक प्रवेश होता. वाड्याच्या ह्या बैठकीत बसणारा बबन माने म्हणजे गावाचंच नाहीतर पंचक्रोशीचं चालतं बोलतं दप्तर.. खेडं असलं तरी गावात तरुण भरपूर होते आणि सारे शेती आणि त्याला पूरक व्यवसाय सांभाळून होते. बबन माने त्यातलाच एक हुन्नरी कलाकार.. पण याचं डोकं शेती ऐवजी इतर गोष्टीत जास्त, म्हणजे शेतकऱ्यांसाठी असणाऱ्या अनेक योजना शोधण्यापासून गावातल्या पोरापोरीची सोयरीक जुळवण्यापर्यंत, गावात येणाऱ्या प्रत्येक माणसाची जुजबी माहिती त्याच्यापर्यंत पोचायची, आणि वाड्यात येणार्यांची कुंडली.. आणि हे सगळं व्हायचं ते येणाऱ्या माणसाच्या नकळत. दादाराव पाटलांच्या वाड्यात वर्दळ कायम असायची. खरंतर दादाराव पाटलांचं आणि पाटलीणबाईंचं गावावर निःसीम प्रेम होतं. गाव तस बऱ्यापैकी लहानच होतं. जंगल आणि नदीमुळे गावात यायला जायला एकच रस्ता.. मुख्य हायवे पासून २५ किलोमीटर आत असलेलं हे एकुलतं एक गाव त्या रस्त्यावर होतं. फाट्यावर कायम एक रिक्षा किंवा जीप उभी असायची. त्यासोबत असलेली बबन्याच्या वडलांची चहा पानसुपारीची बारकी झोपडी, सोबतीला गावातलाच एखादा पोरगा दिवसभर आळीपाळीने असायचा.. तो आणि बबन्याचा बा सोडता माणसाचा मागमूस नाही. बबन्याचा बाप तसा सतत व्यस्त असायचा.. काथ्याचा दोर वळण्यात त्याचा हात कुणीच धरायचं नाही. बसल्या बसल्या दोर बनवायचा तर फाट्यावर झोपडीत बसून दोर वळ म्हणाला बबन्या. शिवाय एक अस्सल कारवानी उमदं कुत्रं आणून ठेवलं होतं ते एक. जनावर असं कि २००-३०० मीटर पासून जरी अनोळखी वास आला तर न भुकता बबन्याच्या बापाला जाऊन बरोबर सांगायचं. मग येणाऱ्या माणसाला थांबवून, पैसे देत असला तर विकत नाहीतर फुकट चहा पाजून बबन्याचा बाप, आलेला माणूस कोण, कुठला, गावात काय काम, किती दिस राहणार वगैरे बित्तम् बातमी काढायचा.. आपणच रघुला म्हणजे गावच्या रिक्षावाल्याला आवाज द्यायचा आणि गावात धाडायचा.. टोलनाकाच म्हणा ना.. एकुणात गाव आणि गावची माणसं बाकी जगापासून अलिप्तच राहायची..\n",
        "# एका सधन गावातले सधन आदर्श शेतकरी हीच ओळख दादांची जपली गेली त्यात बबनचा हात मोठा होता. दादांच्याकडे येणारी इतर कामे बबनकडून येत. कामाच्या काठिण्य पातळीनुसार माणूस ठरवला जाई. टेक्नॉलॉजिचा भरपूर वापर होत असला तरी तो कुठे करायचा आणि कुठे नाही याची जाणीव दादांना होती. काही कामे पैश्यांसाठी तर काही कामे निव्वळ माणुसकीपोटी केली जात होती.\n",
        "# पुण्यासारख्या मोठ्या शहरात एका गरीब पण होतकरू मुलाच्या घरात दिलेली वाघदर्याची मुलगी सुप्रिया, सुप्रियेच्या कॉलनीतली ती मुलगी जेव्हा रडत रडत घरी आली तेव्हा सुप्रिया वाण्याच्या दुकानात काहीतरी घ्यायला गेलेली. संध्याकाळी वेळ. आणि मुलीची एकंदर अवस्था पाहून सुप्रियेला गलबलून आलं. जेमतेम १७ वर्षाची ती नाजूक पोर, विस्कटलेले केस, ड्रेस पाठीवर फाटलेला, रक्ताळलेला ओठ. वाघदऱ्याच्या सुरक्षित वातावरणात वाढलेली सुप्रियेच्या काळजात चर्रर्र झालं. दोन वर्षांपूर्वी या वस्तीत आली असली तरी ती सगळ्यांना ओळखत होती. सुप्रिया त्या मुलीच्या- आरतीच्या पाठोपाठ घरी गेली. झाला प्रकार सांगायला आरती तयार नव्हती, पण सुप्रियेच्या मायेच्या स्पर्शाने तिला वाचा फुटली. जसजशी आरती सांगत होती, तसतशी सुप्रिया एकाच वेळी दुखावत आणि संतापत होती. सगळं ऐकून घेतल्यावर सुप्रियेने घरचा रस्ता धरला.. मनात साठवून ठेवलेलं सारं काही घरी पोचल्याबरोबर तिने तिच्या आईला भडाभडा सांगून टाकलं.. आणि तिच्या आईने वाड्याचा रस्ता धरला..\n",
        "# सुप्रियाच्या आईने जशी सगळी हकीकत बबन्याला वाड्याच्या बैठकीत ऐकवली तशी ती निर्धास्त झाली. नाही म्हणायला तिलाही वाटलं होतंच कि असल्या गुंड असलेल्या वस्तीत आपली मुलगी कशी राहील.. पण वाड्यावर एकदा विषय पोहचला कि गावातलं कुणीही असो, ते निर्धास्त व्हायचे. बबन्याने लगोलग दादाराव पाटलांना वर्दी दिली. दादांनी सगळ्यात आधी आपला हुकमी एक्का जॉनीला परस्पर पुण्याला पाठवलं. जॉनी म्हणजे कोण तर गर्दीतला अनोळखी, लक्षात न राहणारा चेहरा. याचं खरं नाव कुणालाही माहित नव्हतं. जॉनीला ज्यांनी एकदा पाहिलं असेल ते दुसऱ्यांदा त्याला पाहिल्यावर ओळ्खतीलच अशी खात्री नव्हती इतका तो गर्दीत मिसळून जायचा. जॉनी पुण्याला पोहचला आणि कपडे- वेष बदलत एक दिवस मोन्याच्या मागोमाग फिरत त्याची माहिती काढत राहिला.. इकडे वाड्यावर दादांनी गावातला वैदू, सरकारी दवाखान्यातला डॉक्टर आणि बबन्याला घेऊन मिटिंग घेतली. वैदू वाड्याच्या मागच्या बाजूने जंगलात गेला, डॉक्टर आपल्या दवाखान्यात आणि बबन्याने गावातल्या भूषणला बोलावून घेतलं.. जॉनीने एव्हाना ठरल्या प्रोटोकॉलनुसार पुणे स्टेशनवर जाऊन मुंबई जाणारी गाडी पकडली. साधा कीपॅड मोबाईल असलेलं एक सावज हेरून त्याचा मोबाईल चोरला, आणि बबन्याला फोन करून म्हणाला कि \"हैवानानं पोसलेला लांडगा, पिसाळून गेलाय\" उत्तरादाखल बबनने फक्त म्हटलं, \"पत्र पाठवतो\". स्टेशनला उतरताना तो कीपॅड मोबाईल त्याच्या मूळ मालकाच्या पिशवीत पुन्हा पोहचला होता.\n",
        "# दुसऱ्या दिवशी भूषण पुणे स्टेशनजवळ पोस्ट ऑफिसला पोहचला त्याने जॉनीला दुरूनच हेरलं आणि बॅगमधून एक पाकीट काढून ते सहज जॉनीपर्यंत पोचते करून तो आल्यापावली निघून गेला.\n",
        "# पाकिटात एक लहानशी सिरिंज होती, ज्यात वैदूने दिलेला धोत्रा बियांचा विशुद्ध अर्क, आणि डॉक्टरने दिलेले स्ट्रॉंग aphrodisiac होते. लहानात लहान मात्रासुद्धा रक्तदाब वाढवून जीव घेईल असं ते जहाल इंजेक्शन होतं. रात्री चायनीजच्या गाड्याच्या जवळपासच ७ वाजल्यापासूनच जॉनी आपल्या शिकारीची वाट पाहत बसला होता. एक लहानसा धक्का, बारीकशी अगदी मच्छर चावला कि मुंगी अशी वाटावी अशी कळ, आणि थेट मुख्य धमनीत पोहोचलेलं ते जहाल विष.. मोन्याचा विषय आटोपला असला तरी त्याचा मालक अजून बाकी होता..\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "NVxTdnq8SOEp"
      },
      "outputs": [],
      "source": [
        "# marathi_text = \"\"\"\n",
        "# “ए आज्जी मी आलो !”\n",
        "# मोठ्याने आरोळी ठोकत मी माजघर ओलांडून देवघराकडे धाव घेई.आजी तिथे नक्की असणार हे माहित होते.हातातील वही व पोथी बाजूला ठेवून आजी प्रेमाने माझे स्वागत करीत असे .”सुनील किती वाळलास रे ” ,म्हणून गालावरून हात फिरवे आणि स्वत:च्या कानशिलावर बोट मोडत असे .मामाकडून आजोळहून घरी आल्यावर हा नेहमीच पहिला सीन असे .मग सुटीतील दोन महिण्याच्या गैरहजरीचा मोबदला सव्याज मिळत असे .\n",
        "# घरातील कामात आईला मदत केल्यावर आजीचा बहुतेक मुक्काम देवघरात असे .दिवाबत्ती, देवपूजा सारा जिम्मा तिच्याकडे असे . संध्याकाळी ती देवळात जायची ,तिथेच जुन्या मैत्रिणी बरोबर बोलायची तेवढे सोडले कि मग बाकी ना कुणाच्या अध्यातमध्यात वा गप्पा टप्पात. तिला त्याची मुळीच आवड नव्हती .पण उपासतापासाचे मात्र तिला वेड होते .त्यामुळे तिच्याकडे एक उपासाचे लाडू व सुक्या मेवा ठेवायचा डब्बा नेहमी असे .तिला तो खातांना मी कधीच पहिला नव्हता परंतु आमचा मात्र त्यावर केव्हाही हक्क असे . शाळा, खेळ, अभ्यास या साऱ्यातून आजी साठी वेळ मुद्दाम काढावा लागायचा नाही .ती या साऱ्यात अंतर्भूत असायची.खरतर माझे पानही तिच्या शिवाय हलत नसे .\n",
        "# आजीला दोन सवयी होत्या ते म्हणजे साध पान खायची अन वहीत राम राम लिहित बसायची पानाचा तो वेगळा गंध नेहमी तिच्या कपड्याला येत असे .मी त्या लिहिण्या वरून तिला नेहमी चिडवत असे,म्हणायचो “अगं आजी, असे राम राम लिहून का कुठे राम मिळतो ? तू उगाच शाई आणि वह्या वाया घालवतेस बघ “. आजी माझ्याकडे बघून गोड हसे आणि मला डब्यातला एक लाडू वा सुकामेवा देत असे .तिच्या गोड हसण्यामुळे अन लाडूच्या प्रसादाने चर्चा वाढत नसे .मला नेहमी वाटे आजीला समजावून सांगायला पाहिजे .असे राम राम लिहून बोट व पाठ दुखून का घेतेस .पण ते सांगणे या एका वाक्याच्या पुढे कधी गेलेच नाही\n",
        "# पुढे आम्ही शहरात आलो .आजी मात्र गावी तिकडेच राहिली .सुटीत भेटी गाठी होत असत .प्रेमाचे उधान येत असे .हळू हळू थकलेली आजी कालप्रवाहात विरघळून गेली .तिचे जाणे हृदयात मोठी पोकळी निर्माण करून गेले .पण ती जाणार हे तिला, आम्हा सर्वांना माहित होते .तिच्या जाण्यात आजारपण नव्हते ,दु:ख नव्हते ,वेदना नव्हत्या पान गळून पडावे तशी आजी गेली .\n",
        "# गावातील घर बंद झाले ,येणे जाणे हि कमी झाले .बऱ्याच वर्षांनी एकदा गावी गेलो .सात बाराचे जुने उतारे आणायला ,रहिवासाचा दाखला काढणे आणि इतर काही अत्यावश्यक कामा करता .घर साफ करून घेतले .जुन्या आठवणीत मन बुडून गेले .\n",
        "# जुन्या लोखंडी पेटीत पेपर शोधत होतो ,अचानक आजीच्या त्या रामनामाच्या वह्या सापडल्या .एका ओळीत लिहलेल्या काहीही खाडाखोड नसलेल्या .स्पष्ट रेखीव सुंदर जणू एकेक अक्षर कोरून काढलेल्या .माझ्या डोळ्यात पाणी आले .आजीच्या आठवणी फेर धरून नाचू लागल्या .ते माझे बोलणे आठवले “आजी कश्याला उगाच सदानकदा लिहित असतेस हे”.त्यावर आजीचे हसणे जणू कालचीच गोष्ट वाटू लागली .प्रेमाने हृदयाशी धरलेल्या त्या वह्या मी पुन्हा उघडून पाहू लागलो .त्या प्रत्येक वहीच्या पहिल्या पानावर संकल्प होता सुनीलच्या आरोग्य, जय, लाभ, यश, कीर्तीसाठी .माझ्या गळ्यात हुंदका दाटून आला ,आणि डोळ्यातून पुन्हा अश्रू धारा वाहू लागल्या .\n",
        "# त्या रात्री या घटनेमुळे असेल कदाचित ,मला एक स्वप्न पडले .त्या देवघरात आजी बसली आहे.राम नाम लिहित .आणि मी नेहमी सारखा तिथे धावत जातो आज्जी म्हणून ओरडत आणि तिच्या मांडीवर डोके ठेवतो .आणि मला जाणवले अरे हे तर मी बघतो आहे अचानक मला मी ते दृश बघणारा वेगळा अशी जाणीव होवू लागली .आता आजीच्या मांडीवर मी नव्हतो .एक गोरापान अतिशय सुंदर मुलगा तिथे लोळत होता आणि आजी त्याला लिहिता लिहिता थोपटत होती .मला राग आला माझ्या जागेवर आणखी कुणीतरी झोपलाय आणि आजीला कळत कसे नाही .मी जोराने ओरडून सांगायचे ठरवले पण माझा आवाज मलाच एकू येईना .मला काही सुचेना .त्या मुलाकडे तो कोण आहे या बद्दल ची उत्सुकता ,त्याचा राग, हेवा अश्या भावनांनी मन भरले होते .तोच त्या मुलाचे माझ्याकडे लक्ष्य गेले .तो तसाच लोळत माझ्याकडे बघत हसला आणि कुणी तरी कानात बोलले “रामलला” !! मी दचकून उठलो .अंगावर रोमांच उभे राहिले ,डोळ्यातून अश्रूंचा पूर वाहू लागला.आजीच्या साध्या पानाचा दरवळ सभोवताली दाटून राहिला होता .\n",
        "# विक्रांत प्रभाकर\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "l9X6w-a_Rdaf",
        "outputId": "2c0dd38e-62ae-4638-b633-f630f18a6e17"
      },
      "outputs": [],
      "source": [
        "# summary = summarize_marathi_text(marathi_text, 10)\n",
        "# # print(summary)\n",
        "# summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNy53Cisr-pi"
      },
      "source": [
        "# Method 2: User input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "BNy53Cisr-pi"
      },
      "outputs": [],
      "source": [
        "# marathi_text = input(\"Enter your Marathi text:\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_74RaF_SN-Q",
        "outputId": "93039337-d45a-47b3-bf34-cca382adc108"
      },
      "outputs": [],
      "source": [
        "# num_sentences = int(input(\"Enter the desired number of sentences for the summary: \"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEpBwH8VsbeA",
        "outputId": "0f000fad-8aa6-4110-b93b-143cf30f9900"
      },
      "outputs": [],
      "source": [
        "# # Summarize the text\n",
        "# summary = summarize_marathi_text(marathi_text, num_sentences)\n",
        "# print(\"Summary:\")\n",
        "# print(summary)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
